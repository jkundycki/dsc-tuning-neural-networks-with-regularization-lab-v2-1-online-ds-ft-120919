{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df_sample['Product']\n",
    "X = df_sample['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='SGD', \n",
    "                       loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.9417 - accuracy: 0.1615 - val_loss: 1.9388 - val_accuracy: 0.1680\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.9206 - accuracy: 0.1889 - val_loss: 1.9208 - val_accuracy: 0.1890\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.9013 - accuracy: 0.2099 - val_loss: 1.9027 - val_accuracy: 0.2090\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.8798 - accuracy: 0.2355 - val_loss: 1.8817 - val_accuracy: 0.2340\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.8550 - accuracy: 0.2567 - val_loss: 1.8582 - val_accuracy: 0.2550\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.8273 - accuracy: 0.2764 - val_loss: 1.8318 - val_accuracy: 0.2760\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.7967 - accuracy: 0.2983 - val_loss: 1.8021 - val_accuracy: 0.2980\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.7635 - accuracy: 0.3232 - val_loss: 1.7706 - val_accuracy: 0.3020\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.7273 - accuracy: 0.3411 - val_loss: 1.7337 - val_accuracy: 0.3290\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6879 - accuracy: 0.3725 - val_loss: 1.6940 - val_accuracy: 0.3500\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6458 - accuracy: 0.3961 - val_loss: 1.6519 - val_accuracy: 0.3970\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6006 - accuracy: 0.4317 - val_loss: 1.6033 - val_accuracy: 0.4220\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5525 - accuracy: 0.4636 - val_loss: 1.5558 - val_accuracy: 0.4570\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5029 - accuracy: 0.4912 - val_loss: 1.5060 - val_accuracy: 0.4870\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4517 - accuracy: 0.5260 - val_loss: 1.4574 - val_accuracy: 0.5100\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4006 - accuracy: 0.5532 - val_loss: 1.4044 - val_accuracy: 0.5390\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3501 - accuracy: 0.5757 - val_loss: 1.3557 - val_accuracy: 0.5620\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2998 - accuracy: 0.5997 - val_loss: 1.3091 - val_accuracy: 0.5860\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2520 - accuracy: 0.6213 - val_loss: 1.2604 - val_accuracy: 0.6100\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.2055 - accuracy: 0.6392 - val_loss: 1.2163 - val_accuracy: 0.6350\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1613 - accuracy: 0.6547 - val_loss: 1.1733 - val_accuracy: 0.6460\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.1195 - accuracy: 0.6715 - val_loss: 1.1374 - val_accuracy: 0.6450\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0801 - accuracy: 0.6809 - val_loss: 1.0967 - val_accuracy: 0.6630\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.0428 - accuracy: 0.6936 - val_loss: 1.0630 - val_accuracy: 0.6620\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0081 - accuracy: 0.7017 - val_loss: 1.0292 - val_accuracy: 0.6690\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9765 - accuracy: 0.7073 - val_loss: 1.0006 - val_accuracy: 0.6780\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9467 - accuracy: 0.7133 - val_loss: 0.9746 - val_accuracy: 0.6840\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9193 - accuracy: 0.7195 - val_loss: 0.9495 - val_accuracy: 0.6870\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8936 - accuracy: 0.7228 - val_loss: 0.9252 - val_accuracy: 0.6960\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8697 - accuracy: 0.7279 - val_loss: 0.9032 - val_accuracy: 0.6950\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8482 - accuracy: 0.7315 - val_loss: 0.8859 - val_accuracy: 0.6980\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8280 - accuracy: 0.7360 - val_loss: 0.8685 - val_accuracy: 0.6970\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8095 - accuracy: 0.7381 - val_loss: 0.8505 - val_accuracy: 0.7100\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7923 - accuracy: 0.7427 - val_loss: 0.8376 - val_accuracy: 0.7040\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7762 - accuracy: 0.7444 - val_loss: 0.8218 - val_accuracy: 0.7110\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7613 - accuracy: 0.7489 - val_loss: 0.8112 - val_accuracy: 0.7040\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7476 - accuracy: 0.7497 - val_loss: 0.8041 - val_accuracy: 0.7070\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7345 - accuracy: 0.7512 - val_loss: 0.7898 - val_accuracy: 0.7120\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7226 - accuracy: 0.7540 - val_loss: 0.7796 - val_accuracy: 0.7210\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7112 - accuracy: 0.7567 - val_loss: 0.7719 - val_accuracy: 0.7160\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7001 - accuracy: 0.7619 - val_loss: 0.7634 - val_accuracy: 0.7110\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.6905 - accuracy: 0.7633 - val_loss: 0.7581 - val_accuracy: 0.7150\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6809 - accuracy: 0.7651 - val_loss: 0.7493 - val_accuracy: 0.7230\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.6714 - accuracy: 0.7675 - val_loss: 0.7442 - val_accuracy: 0.7240\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.6627 - accuracy: 0.7712 - val_loss: 0.7351 - val_accuracy: 0.7220\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6545 - accuracy: 0.7729 - val_loss: 0.7329 - val_accuracy: 0.7160\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.6468 - accuracy: 0.7752 - val_loss: 0.7273 - val_accuracy: 0.7210\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6393 - accuracy: 0.7769 - val_loss: 0.7217 - val_accuracy: 0.7210\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6320 - accuracy: 0.7804 - val_loss: 0.7140 - val_accuracy: 0.7240\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6250 - accuracy: 0.7821 - val_loss: 0.7148 - val_accuracy: 0.7260\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6177 - accuracy: 0.7845 - val_loss: 0.7072 - val_accuracy: 0.7290\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6117 - accuracy: 0.7871 - val_loss: 0.7036 - val_accuracy: 0.7230\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6053 - accuracy: 0.7868 - val_loss: 0.7030 - val_accuracy: 0.7300\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5992 - accuracy: 0.7909 - val_loss: 0.6946 - val_accuracy: 0.7310\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5932 - accuracy: 0.7913 - val_loss: 0.6979 - val_accuracy: 0.7260\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5879 - accuracy: 0.7927 - val_loss: 0.6932 - val_accuracy: 0.7310\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5820 - accuracy: 0.7949 - val_loss: 0.6901 - val_accuracy: 0.7300\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5767 - accuracy: 0.7959 - val_loss: 0.6887 - val_accuracy: 0.7300\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5713 - accuracy: 0.7963 - val_loss: 0.6822 - val_accuracy: 0.7280\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5658 - accuracy: 0.8005 - val_loss: 0.6815 - val_accuracy: 0.7280\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5612 - accuracy: 0.8008 - val_loss: 0.6749 - val_accuracy: 0.7300\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5565 - accuracy: 0.8023 - val_loss: 0.6766 - val_accuracy: 0.7390\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5516 - accuracy: 0.8045 - val_loss: 0.6730 - val_accuracy: 0.7320\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5467 - accuracy: 0.8068 - val_loss: 0.6711 - val_accuracy: 0.7350\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.5418 - accuracy: 0.8083 - val_loss: 0.6668 - val_accuracy: 0.7370\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5376 - accuracy: 0.8096 - val_loss: 0.6642 - val_accuracy: 0.7380\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5329 - accuracy: 0.8105 - val_loss: 0.6689 - val_accuracy: 0.7380\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5288 - accuracy: 0.8124 - val_loss: 0.6637 - val_accuracy: 0.7380\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5241 - accuracy: 0.8159 - val_loss: 0.6629 - val_accuracy: 0.7430\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5204 - accuracy: 0.8151 - val_loss: 0.6600 - val_accuracy: 0.7390\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5156 - accuracy: 0.8176 - val_loss: 0.6648 - val_accuracy: 0.7430\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5123 - accuracy: 0.8176 - val_loss: 0.6619 - val_accuracy: 0.7380\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5080 - accuracy: 0.8185 - val_loss: 0.6559 - val_accuracy: 0.7390\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5036 - accuracy: 0.8195 - val_loss: 0.6564 - val_accuracy: 0.7410\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4994 - accuracy: 0.8237 - val_loss: 0.6542 - val_accuracy: 0.7420\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4960 - accuracy: 0.8233 - val_loss: 0.6544 - val_accuracy: 0.7430\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.4914 - accuracy: 0.8261 - val_loss: 0.6567 - val_accuracy: 0.7400\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4884 - accuracy: 0.8276 - val_loss: 0.6566 - val_accuracy: 0.7450\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4847 - accuracy: 0.8297 - val_loss: 0.6528 - val_accuracy: 0.7440\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4809 - accuracy: 0.8303 - val_loss: 0.6497 - val_accuracy: 0.7450\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4771 - accuracy: 0.8316 - val_loss: 0.6489 - val_accuracy: 0.7450\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.4740 - accuracy: 0.8324 - val_loss: 0.6511 - val_accuracy: 0.7440\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.4701 - accuracy: 0.8348 - val_loss: 0.6471 - val_accuracy: 0.7470\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.4666 - accuracy: 0.8355 - val_loss: 0.6487 - val_accuracy: 0.7480\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.4630 - accuracy: 0.8396 - val_loss: 0.6477 - val_accuracy: 0.7530\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.4597 - accuracy: 0.8399 - val_loss: 0.6475 - val_accuracy: 0.7440\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4564 - accuracy: 0.8409 - val_loss: 0.6458 - val_accuracy: 0.7420\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4531 - accuracy: 0.8413 - val_loss: 0.6474 - val_accuracy: 0.7490\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.4494 - accuracy: 0.8449 - val_loss: 0.6449 - val_accuracy: 0.7470\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.4465 - accuracy: 0.8453 - val_loss: 0.6444 - val_accuracy: 0.7450\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4432 - accuracy: 0.8469 - val_loss: 0.6459 - val_accuracy: 0.7460\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.4401 - accuracy: 0.8485 - val_loss: 0.6463 - val_accuracy: 0.7460\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.4368 - accuracy: 0.8473 - val_loss: 0.6471 - val_accuracy: 0.7520\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.4339 - accuracy: 0.8509 - val_loss: 0.6461 - val_accuracy: 0.7540\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4303 - accuracy: 0.8523 - val_loss: 0.6445 - val_accuracy: 0.7520\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.4275 - accuracy: 0.8528 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.4244 - accuracy: 0.8556 - val_loss: 0.6441 - val_accuracy: 0.7530\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.85 - 0s 39us/step - loss: 0.4211 - accuracy: 0.8557 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.4185 - accuracy: 0.8576 - val_loss: 0.6454 - val_accuracy: 0.7480\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4151 - accuracy: 0.8579 - val_loss: 0.6460 - val_accuracy: 0.7490\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4124 - accuracy: 0.8611 - val_loss: 0.6470 - val_accuracy: 0.7470\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4097 - accuracy: 0.8605 - val_loss: 0.6416 - val_accuracy: 0.7520\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4064 - accuracy: 0.8637 - val_loss: 0.6435 - val_accuracy: 0.7530\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4035 - accuracy: 0.8640 - val_loss: 0.6431 - val_accuracy: 0.7510\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4007 - accuracy: 0.8635 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3977 - accuracy: 0.8695 - val_loss: 0.6458 - val_accuracy: 0.7530\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3949 - accuracy: 0.8675 - val_loss: 0.6455 - val_accuracy: 0.7550\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3923 - accuracy: 0.8691 - val_loss: 0.6460 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3893 - accuracy: 0.8708 - val_loss: 0.6548 - val_accuracy: 0.7440\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3870 - accuracy: 0.8725 - val_loss: 0.6501 - val_accuracy: 0.7480\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.3839 - accuracy: 0.8735 - val_loss: 0.6547 - val_accuracy: 0.7470\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3815 - accuracy: 0.8747 - val_loss: 0.6462 - val_accuracy: 0.7540\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.3785 - accuracy: 0.8763 - val_loss: 0.6544 - val_accuracy: 0.7490\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.3761 - accuracy: 0.8756 - val_loss: 0.6498 - val_accuracy: 0.7560\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 0.3732 - accuracy: 0.8775 - val_loss: 0.6439 - val_accuracy: 0.7550\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.3708 - accuracy: 0.8793 - val_loss: 0.6483 - val_accuracy: 0.7500\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.3684 - accuracy: 0.8788 - val_loss: 0.6485 - val_accuracy: 0.7510\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.3654 - accuracy: 0.8809 - val_loss: 0.6470 - val_accuracy: 0.7550\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3632 - accuracy: 0.8831 - val_loss: 0.6512 - val_accuracy: 0.7540\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3604 - accuracy: 0.8839 - val_loss: 0.6522 - val_accuracy: 0.7520\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3579 - accuracy: 0.8847 - val_loss: 0.6520 - val_accuracy: 0.7540\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.3558 - accuracy: 0.8860 - val_loss: 0.6525 - val_accuracy: 0.7520\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.3530 - accuracy: 0.8859 - val_loss: 0.6598 - val_accuracy: 0.7530\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3512 - accuracy: 0.8876 - val_loss: 0.6511 - val_accuracy: 0.7590\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3485 - accuracy: 0.8884 - val_loss: 0.6565 - val_accuracy: 0.7520\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.3460 - accuracy: 0.8899 - val_loss: 0.6553 - val_accuracy: 0.7530\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3434 - accuracy: 0.8917 - val_loss: 0.6505 - val_accuracy: 0.7560\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3411 - accuracy: 0.8929 - val_loss: 0.6511 - val_accuracy: 0.7550\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.3386 - accuracy: 0.8921 - val_loss: 0.6520 - val_accuracy: 0.7540\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3364 - accuracy: 0.8929 - val_loss: 0.6515 - val_accuracy: 0.7550\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3341 - accuracy: 0.8959 - val_loss: 0.6577 - val_accuracy: 0.7540\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.3321 - accuracy: 0.8948 - val_loss: 0.6588 - val_accuracy: 0.7560\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.3301 - accuracy: 0.8975 - val_loss: 0.6585 - val_accuracy: 0.7540\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3275 - accuracy: 0.8993 - val_loss: 0.6585 - val_accuracy: 0.7580\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3251 - accuracy: 0.9003 - val_loss: 0.6579 - val_accuracy: 0.7560\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.3228 - accuracy: 0.9007 - val_loss: 0.6602 - val_accuracy: 0.7550\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.3205 - accuracy: 0.9011 - val_loss: 0.6573 - val_accuracy: 0.7560\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3184 - accuracy: 0.9016 - val_loss: 0.6607 - val_accuracy: 0.7570\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3162 - accuracy: 0.9020 - val_loss: 0.6602 - val_accuracy: 0.7560\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.3140 - accuracy: 0.9020 - val_loss: 0.6638 - val_accuracy: 0.7560\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.3121 - accuracy: 0.9039 - val_loss: 0.6639 - val_accuracy: 0.7560\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.3098 - accuracy: 0.9047 - val_loss: 0.6637 - val_accuracy: 0.7560\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.3075 - accuracy: 0.9039 - val_loss: 0.6637 - val_accuracy: 0.7570\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.3057 - accuracy: 0.9061 - val_loss: 0.6672 - val_accuracy: 0.7540\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.3036 - accuracy: 0.9073 - val_loss: 0.6648 - val_accuracy: 0.7580\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3014 - accuracy: 0.9089 - val_loss: 0.6643 - val_accuracy: 0.7590\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.2991 - accuracy: 0.9107 - val_loss: 0.6702 - val_accuracy: 0.7550\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2973 - accuracy: 0.9092 - val_loss: 0.6698 - val_accuracy: 0.7600\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2955 - accuracy: 0.9112 - val_loss: 0.6725 - val_accuracy: 0.7580\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.2933 - accuracy: 0.9119 - val_loss: 0.6733 - val_accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, \n",
    "                                        y_train_lb, \n",
    "                                        epochs=150, \n",
    "                                        batch_size=256, \n",
    "                                        validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 26us/step\n",
      "----------\n",
      "Training Loss: 0.291 \n",
      "Training Accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 33us/step\n",
      "----------\n",
      "Test Loss: 0.609 \n",
      "Test Accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = baseline_model_val_dict['loss']\n",
    "val_loss_values = baseline_model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "ax.plot(epochs, loss_values, label='Training loss')\n",
    "ax.plot(epochs, val_loss_values, label='Validation loss')\n",
    "\n",
    "ax.set_title('Training & validation loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3zV5fn/8dd9stfJHiSQwQwrCSGADJlKwTIUUUTRYktt+3W1dtFqf+Joa92jaqtWqxZFq1XEKtaBIoLsvUcSyCB7r5Nzzv374z5ZkLBMCAnX8/HIg5xzPuP+nKC8c5/rc91Ka40QQgghhBDizFg6ewBCCCGEEEJ0JRKghRBCCCGEOAsSoIUQQgghhDgLEqCFEEIIIYQ4CxKghRBCCCGEOAsSoIUQQgghhDgLEqCFEN2CUspNKVWplIptz20vdEqpfymllri+n6iU2n0m257DebrNeyaEEN+VBGghRKdwhbGGL6dSqqbZ4xvO9nhaa4fW2l9rfbQ9tz0XSqkRSqktSqkKpdQ+pdRlHXGeE2mtv9RaD26PYyml1iilFjY7doe+Z0II0ZVIgBZCdApXGPPXWvsDR4GZzZ5beuL2Sin38z/Kc/Yc8AFgBa4Asjt3OKItSimLUkr+LRRCnBX5n4YQ4oKklHpQKfWWUupNpVQFsEApNVop9a1SqlQplauUelop5eHa3l0ppZVS8a7H/3K9/rFrJnidUirhbLd1vT5dKXVAKVWmlHpGKfVN89nZVtiBTG0c0VrvPc21HlRKTWv22FMpVayUSnIFvHeUUsdd1/2lUmpgG8e5TCmV0ezxcKXUNtc1vQl4NXstVCn1kVKqQClVopRaoZSKcb32F2A08DfXJwJPtvKeBbnetwKlVIZS6ndKKeV6bZFS6iul1BOuMR9RSk09xfXf49qmQim1Wyk164TXf+Kaya9QSu1SSiW7no9TSr3vGkOhUuop1/MPKqX+2Wz/vkop3ezxGqXUA0qpdUAVEOsa817XOQ4rpRadMIY5rveyXCl1SCk1VSk1Xym1/oTtfquUeqetaxVCdA8SoIUQF7KrgDeAQOAtTDC9EwgDxgLTgJ+cYv/rgT8AIZhZ7gfOdlulVATwNvBr13nTgZGnGfcG4LGGoHcG3gTmN3s8HcjRWu9wPf4Q6AdEAbuA1093QKWUF7AceBlzTcuBK5ttYgFeBGKBOKAeeApAa/1bYB3wU9cnAj9v5RTPAb5Ab2Ay8CPgpmavjwF2AqHAE8A/TjHcA5ifZyDwR+ANpVSk6zrmA/cAN2Bm9OcAxa5PJP4LHALigV6Yn9OZuhH4oeuYWUAe8H3X4x8DzyilklxjGIN5H38JBAGTgEzgfWCAUqpfs+Mu4Ax+PkKIrk0CtBDiQrZGa71Ca+3UWtdorTdqrddrre1a6yPAC8CEU+z/jtZ6k9a6HlgKpJzDtjOAbVrr5a7XngAK2zqIUmoBJgwuAP7bLIRNP3G2spk3gCuVUt6ux9e7nsN17f/UWldorWuBJcBwpZTfKa4F1xg08IzWul5rvQzY2vCi1rpAa/2e630tB/7Eqd/L5tfoAVwLLHaN6wjmfbmx2WaHtdYva60dwKtAT6VUWGvH01q/rbXOdV3rG0AGkOZ6eRHwkNZ6s2tG/4DW+hhmhjwM+K3Wusp1Hd+cyfhdXtZa73W9N3bX37MjrnN8AXwOXOra9kfAi1rrz11jPKa13q+1rgH+jflZo5RKAXoAH53FOIQQXZAEaCHEhexY8wdKqUSl1H9d5QzlwP2YENWW482+rwb8z2Hb6Obj0FprzIxlW+4EntZafwTcCvzPFaLHAJ+1toPWeh9wGPi+UsofE9rfgMbuFw+7ShzKMTOucOrrbhh3lmu8DTIbvlFK+SmlXlJKHXUd94szOGaDCMCt+fFc38c0e3zi+wltvP9KqYVKqe2uco9SILHZWHph3psT9QIyXAH9XJz4d2uGUmq9q3SmFJh6BmMA88tBw02vC4C3XL9oCSG6MQnQQogLmT7h8d8xJQx9tdZW4P8BqoPHkAv0bHjgqvONaXtz3DGlJmitlwO/xQTnBcCTp9ivoYzjKsyMd4br+ZswNyJOxpQ49G0YytmM26V5C7rfAAnASNd7OfmEbU9875vLBxyY0o/mxz7rmyWVUr2B54GfAaFa6yBgH03Xdwzo08qux4A4pZRbK69VYcpLGkS1sk3zmmgf4B3gz0Ckawz/O4MxoLVe4zrGWMzPT8o3hLgISIAWQnQlAUAZUOW6ke5U9c/t5UMgVSk101V3eycQfort/w0sUUoNVaa7wz7ABvgA3qfY701M7fMtuGafXQKAOqAIEwr/eIbjXgNYlFK3uW4AvAZIPeG41UCJUioU88tIc3mY+uaTuGZY3wH+pJTyV+aGy18A/zrDsTXnjwmzBZjfTxZhZqAbvAT8Rik1TBn9lFK9MDXaRa4x+CqlfFwhFmAbMEEp1UspFQQsPs0YvABP1xgcSqkZwJRmr/8DWKSUmqTMTZ09lVIDmr3+OuaXgCqt9bfn8B4IIboYCdBCiK7kl8APgArMbPRbHX1CrXUeMA94HBPY+mBqieva2OUvwGuYNnbFmFnnRZiA/F+llLWN82QBm4BLaHkz3CtAjutrN7D2DMddh5nN/jFQgrn57v1mmzyOmdEuch3z4xMO8SQw31VW8Xgrp/g/zC8G6cBXmFKG185kbCeMcwfwNObGy1xMeF7f7PU3Me/pW0A58B8gWGttx5S6DMTMEB8F5rp2Wwm8h7mJcQPmZ3GqMZRifgF4D/Mzm4v5xanh9bWY9/FpzC9wqzBlHQ1eA4Ygs89CXDRUy/I4IYQQp+IqGcgB5mqtv+7s8YjO57qhMx8YorVO7+zxCCE6nsxACyHEaSilpimlAl2t4f6AqXHe0MnDEheOW4FvJDwLcfHoSit7CSFEZxmHaW3niSmjuNJVIiEuckqpLEwP7dmdPRYhxPkjJRxCCCGEEEKcBSnhEEIIIYQQ4ixIgBZCCCGEEOIsdLka6LCwMB0fH9/ZwxBCCCGEEN3c5s2bC7XWJ/X+73IBOj4+nk2bNnX2MIQQQgghRDenlMps7Xkp4RBCCCGEEOIsSIAWQgghhBDiLEiAFkIIIYQQ4ix0uRro1tTX15OVlUVtbW1nD0VcQLy9venZsyceHh6dPRQhhBBCdCPdIkBnZWUREBBAfHw8SqnOHo64AGitKSoqIisri4SEhM4ejhBCCCG6kW5RwlFbW0toaKiEZ9FIKUVoaKh8KiGEEEKIdtctAjQg4VmcRP5OCCGEEKIjdJsA3ZmKiopISUkhJSWFqKgoYmJiGh/bbLYzOsbNN9/M/v37T7nNs88+y9KlS9tjyEIIIYQQ4hx1ixrozhYaGsq2bdsAWLJkCf7+/vzqV79qsY3WGq01Fkvrv7O88sorpz3Prbfe+t0He57Z7Xbc3eWvmRBCCCG6D5mB7kCHDh1iyJAh/PSnPyU1NZXc3FxuueUW0tLSGDx4MPfff3/jtuPGjWPbtm3Y7XaCgoJYvHgxycnJjB49mvz8fADuuecennzyycbtFy9ezMiRIxkwYABr164FoKqqiquvvprk5GTmz59PWlpaY7hv7t5772XEiBGN49NaA3DgwAEmT55McnIyqampZGRkAPCnP/2JoUOHkpyczN13391izADHjx+nb9++ALz00ktcd911zJgxg+nTp1NeXs7kyZNJTU0lKSmJDz/8sHEcr7zyCklJSSQnJ3PzzTdTWlpK7969sdvtAJSWlpKQkIDD4Wi3n4sQQgghxHfR7aYG71uxmz055e16zEHRVu6dOfic9t2zZw+vvPIKf/vb3wB46KGHCAkJwW63M2nSJObOncugQYNa7FNWVsaECRN46KGHuOuuu3j55ZdZvHjxScfWWrNhwwY++OAD7r//flauXMkzzzxDVFQU7777Ltu3byc1NbXVcd15553cd999aK25/vrrWblyJdOnT2f+/PksWbKEmTNnUltbi9PpZMWKFXz88cds2LABHx8fiouLT3vd69atY9u2bQQHB1NfX8/y5csJCAggPz+fsWPHMmPGDLZv385f/vIX1q5dS0hICMXFxQQFBTF27FhWrlzJjBkzeOONN7j22mtxc3M7h3dfCCGEEKL9yQx0B+vTpw8jRoxofPzmm2+SmppKamoqe/fuZc+ePSft4+Pjw/Tp0wEYPnx44yzwiebMmXPSNmvWrOG6664DIDk5mcGDWw/+n3/+OSNHjiQ5OZmvvvqK3bt3U1JSQmFhITNnzgRMH2VfX18+++wzfvjDH+Lj4wNASEjIaa976tSpBAcHAybo//a3vyUpKYmpU6dy7NgxCgsL+eKLL5g3b17j8Rr+XLRoUWNJyyuvvMLNN9982vMJIYQQQpwv3W4G+lxnijuKn59f4/cHDx7kqaeeYsOGDQQFBbFgwYJW26x5eno2fu/m5tZYznAiLy+vk7ZpKMU4lerqam677Ta2bNlCTEwM99xzT+M4WutcobVu9Xl3d3ecTifASdfR/Lpfe+01ysrK2LJlC+7u7vTs2ZPa2to2jzthwgRuu+02Vq1ahYeHB4mJiae9JiGEEEKI80VmoM+j8vJyAgICsFqt5Obm8sknn7T7OcaNG8fbb78NwM6dO1ud4a6pqcFisRAWFkZFRQXvvvsuAMHBwYSFhbFixQrAhOLq6mqmTp3KP/7xD2pqagAaSzji4+PZvHkzAO+8806bYyorKyMiIgJ3d3c+/fRTsrOzAbjssstYtmxZ4/Gal4YsWLCAG264QWafhRBCCHHBkQB9HqWmpjJo0CCGDBnCj3/8Y8aOHdvu57j99tvJzs4mKSmJxx57jCFDhhAYGNhim9DQUH7wgx8wZMgQrrrqKkaNGtX42tKlS3nsscdISkpi3LhxFBQUMGPGDKZNm0ZaWhopKSk88cQTAPz617/mqaeeYsyYMZSUlLQ5phtvvJG1a9eSlpbGv//9b/r16wdAUlISv/nNbxg/fjwpKSn8+te/btznhhtuoKysjHnz5rXn2yOEEEII8Z2pM/nI/0KSlpamN23a1OK5vXv3MnDgwE4a0YXFbrdjt9vx9vbm4MGDTJ06lYMHD3a5VnLLli3jk08+OaP2fqcifzeEEEIIca6UUpu11mknPt+1UpU4rcrKSqZMmYLdbkdrzd///vcuF55/9rOf8dlnn7Fy5crOHooQQgghOpHd4aSspp5Qf6/OHkoLXStZidMKCgpqrEvuqp5//vnOHoIQQggh2pHWmmPFNWzLKkVrzeBoKwlh/rhZTDOBsup6vk0vYt3hIvYdL6eo0kZRlY2SahseFgv7H5zWauOBziIBWgghhBBCtKuymnq2HytlW7Ov4ipbi228PSwkRllxODW7csrQ2jw3ODqQPuH+jEzwJNTfizB/TxxOjbubBGghhBBCCNHF1dY7yCiq4khBFYfzKzlUUMnO7DKOFFQBoBT0CfdncmIEKb2CSOkVhJtFsSennN055ezOKQPgzin9GNMnjORegXi5X/iLp3VogFZKTQOeAtyAl7TWD53wehzwMhAOFAMLtNZZHTkmIYQQQgjRNq015bV28sprKaq0EeTrQZTVmyBfD5RSZBZVsWpfPl/sL+DbI0XY7M7GfaMDvRkUbWXOsBhSegWT1CsQq7fHSecY2MPK1cPP51W1rw4L0EopN+BZ4HIgC9iolPpAa928MfGjwGta61eVUpOBPwM3dtSYhBBCCCFEE601hwuq2JBezIb0IrZnlZFbVkNtvfOkbT3dLFh9PCisrAOgd5gfC0bFkRIbRO8wP3qH++HreXEUN3TkVY4EDmmtjwAopZYBs4HmAXoQ8AvX96uA9ztwPB1m4sSJ/O53v+N73/te43NPPvkkBw4c4LnnnmtzP39/fyorK8nJyeGOO+5odTGSiRMn8uijj5KWdlIHlRbnuuWWW/D19QXgiiuu4I033iAoKOg7XJUQQgghLjRaa2rqHVTW2qmos5s/a+1U1tVT0fi9+TKP681j12s19Y4Wx6uoraekuh6AMH8vhscFMSUxgqhAbyKs3oT6eVJaXU9eea2Zka6yMTjayqQBEcSH+bU2xItCRwboGOBYs8dZwKgTttkOXI0p87gKCFBKhWqtizpwXO1u/vz5LFu2rEWAXrZsGY888sgZ7R8dHX3KlfxO58knn2TBggWNAfqjjz4652N1Bq01WmssFlnXRwghhNBac6Swio3pxRwprCK7pIas0hqyS2ooqbbhcJ5+DQ9vDwv+Xh5Yvd3x93bH38ud+DBffDzcWnSz8PawkNIriJEJocSH+l5QnS4uZB0ZoFv7CZz4E/8V8Fel1EJgNZAN2E86kFK3ALcAxMbGtu8o28HcuXO55557qKurw8vLi4yMDHJychg3bhyVlZXMnj2bkpIS6uvrefDBB5k9e3aL/TMyMpgxYwa7du2ipqaGm2++mT179jBw4MDG5bPB9EfeuHEjNTU1zJ07l/vuu4+nn36anJwcJk2aRFhYGKtWrSI+Pp5NmzYRFhbG448/zssvvwzAokWL+PnPf05GRgbTp09n3LhxrF27lpiYGJYvX46Pj0+Lca1YsYIHH3wQm81GaGgoS5cuJTIyksrKSm6//XY2bdqEUop7772Xq6++mpUrV/L73/8eh8NBWFgYn3/+OUuWLMHf359f/epXAAwZMoQPP/wQgOnTpzNp0iTWrVvH+++/z0MPPXTS9QFs3LiRO++8k6qqKry8vPj888+54ooreOaZZ0hJSQFg7NixPP/88yQlJXXMD1kIIYToQPkVtXyy6zjfHCpiU2YxhZWmY4Wnu4WYIB9ignyYkhhBqL8nAd4eBHi7E+AKxgHeHq4/zZeflzsebjIp1ZE6MkBnAb2aPe4J5DTfQGudA8wBUEr5A1drrctOPJDW+gXgBTArEZ7yrB8vhuM7v9PATxI1FKY/1ObLoaGhjBw5kpUrVzJ79myWLVvGvHnzUErh7e3Ne++9h9VqpbCwkEsuuYRZs2a1+Rve888/j6+vLzt27GDHjh2kpqY2vvbHP/6RkJAQHA4HU6ZMYceOHdxxxx08/vjjrFq1irCwsBbH2rx5M6+88grr169Ha82oUaOYMGECwcHBHDx4kDfffJMXX3yRa6+9lnfffZcFCxa02H/cuHF8++23KKV46aWXePjhh3nsscd44IEHCAwMZOdO8z6XlJRQUFDAj3/8Y1avXk1CQgLFxcWnfVv379/PK6+80ljm0tr1JSYmMm/ePN566y1GjBhBeXk5Pj4+LFq0iH/+85+NpTJ1dXUSnoUQQlyQnE7N2sNF/G/PcTMTHOpHbKgvkVZv1h8pYsWOHNYdLsKpISbIh/H9whmZEMKIhBASQv2wWGRW+ELTkQF6I9BPKZWAmVm+Dri++QZKqTCgWGvtBH6H6cjRJTWUcTQE6IZZX601v//971m9ejUWi4Xs7Gzy8vKIiopq9TirV6/mjjvuACApKalFKHz77bd54YUXsNvt5ObmsmfPnlOGxjVr1nDVVVfh52dqlObMmcPXX3/NrFmzSEhIaJy9HT58OBkZGSftn5WVxbx588jNzcVms5GQkADAZ599xrJlyxq3Cw4OZsWKFYwfP75xm5CQkNO+Z3FxcVxyySWnvD6lFD169GDEiBEAWK1WAK655hoeeOABHnnkEV5++WUWLlx42vMJIYQQ7cXp1FTU2bF6u7c6KeZ0ajKKqnhvazbvbs4ip6wWHw836h1O7CeUYCSE+XHbpL7MSI6mf2TA+boE8R10WIDWWtuVUrcBn2Da2L2std6tlLof2KS1/gCYCPxZKaUxJRy3fucTn2KmuCNdeeWV3HXXXWzZsoWamprGmeOlS5dSUFDA5s2b8fDwID4+ntra2lMeq7X/ENPT03n00UfZuHEjwcHBLFy48LTH0brtyXovr6YlMd3c3FqUijS4/fbbueuuu5g1axZffvklS5YsaTzuiWNs7TkAd3d3nM6mO3mbj7kh2J/q+to6rq+vL5dffjnLly/n7bffZtOmTW1eqxBCCPFdlNXUszmzmO3HyjhcUMnhgirSCyuprXfi6WYhPMCLqEBvgnw8KKqykVdeS0FFHXanRim4tF84v7tiIJcPisTdosgprSWz2NQ2D4kJZHC0VWqPu5gO7TWitf4I+OiE5/5fs+/fAc797rkLiL+/PxMnTuSHP/wh8+fPb3y+rKyMiIgIPDw8WLVqFZmZmac8zvjx41m6dCmTJk1i165d7NixA4Dy8nL8/PwIDAwkLy+Pjz/+mIkTJwIQEBBARUXFSSUc48ePZ+HChSxevBitNe+99x6vv/76GV9TWVkZMTExALz66quNz0+dOpW//vWvPPnkk4Ap4Rg9ejS33nor6enpjSUcISEhxMfHN9Y8b9myhfT09FbP1db1JSYmkpOTw8aNGxkxYgQVFRX4+Pjg7u7OokWLmDlzJpdeeukZzXgLIYQQp2N3ODlSWMXunDK2HS1lQ0YJ+46XozVYFPQM9qVPuB9j+oQSZfVuDMx55bXklNUS5u9Jn/AwIq1eRAf5MGVgBD0CW95jFBvqS2yobyddoWgPF0ezvvNk/vz5zJkzp0V5ww033MDMmTNJS0sjJSWFxMTEUx7jZz/7GTfffDNJSUmkpKQwcuRIAJKTkxk2bBiDBw+md+/ejB07tnGfW265henTp9OjRw9WrVrV+HxqaioLFy5sPMaiRYsYNmxYq+UarVmyZAnXXHMNMTExXHLJJY3h95577uHWW29lyJAhuLm5ce+99zJnzhxeeOEF5syZg9PpJCIigk8//ZSrr76a1157jZSUFEaMGEH//v1bPVdb1+fp6clbb73F7bffTk1NDT4+Pnz22Wf4+/szfPhwrFYrN9988xldjxBCCAEmJB/IqyS9sIrj5bXkl9dyvLyWjMIq9h2voM61MIiPhxupcUH8fEp/RiaEkNIrCB/PC3+VPNHx1Kk+5r8QpaWl6RM/rt+7dy8DBw7spBGJzpKTk8PEiRPZt29fmy3w5O+GEEJcXCrr7BzIq+BgXgU1NgdubhY8LAqLRXG0qJotR0vYfqyUKltTP2RPdwuRVi96BfsyONrKoGgrg3oE0ifcD3fpZnFRU0pt1lqftBiHzECLLum1117j7rvv5vHHH5f+0UIIcZFwODVFVXXkl9dxvKyWvIpa8spqySuv43h5LYfyK8kuPfmengZuFkViVABXD+9JamwwA6ICWixRLcSZkgAtuqSbbrqJm266qbOHIYQQogMVV9n4+mABXx8s5NsjReSW1Z60iIhSZgW9SKsXw+OCuX5ULP0jA+gf6Y/V24N6pxOHU2N3aEL9PS+apaZFx5K/RUIIIYS4INjsTrYcLeHrgwWsPlDIrpwytIZAHw/G9Alldko0kVbvZl9ehPt7SZmFOO+6TYBuq92ZuHh1tfp+IYTozqptdrZklrIhvYgNGcUcLqgiwMudQF8PAn080Bo2ZRRTZXPgZlGkxgbxi8v6M75/OENjAnGTxUTEBaRbBGhvb2+KiooIDQ2VEC0AE56Liorw9vbu7KEIIUS3Vmd3sC+3gtKaekL9PAnz9yLEz5Nqm52NGSVszChmfXoxu7PLsDs1FgWDowOZNCCcapuDspp6iqts2OxOrhwWw/j+4YzuE4rV26OzL02INnWLAN2zZ0+ysrIoKCjo7KGIC4i3tzc9e/bs7GEIIUS3oLWmsNLG4YJKjhSYPsk7ssrYd7ycekfbn/h5ullI7hXITyb0ZmRCKKmxQQRIOBZdXLcI0B4eHo1LSAshhBDi3JVW29h6rJSMQrNSXnap+coorKK81t64XYCXO0N7BvKjcb1J6hlIeIAXRZU2iqrqKKq04WZRpMUFk9wrCG8P6Z0supduEaCFEEIIcfYaFhTZdqyULUdL2HK0hCMFVY2ve3tYiAnyITrIh1kp0fQJ9zdfEf70sHpjkbpkcZGSAC2EEEJ0IzuzyvjHmiP0DvdnTJ9QknsF4eHqUpFbVsO2o6VsO1bK1mOl7Mwqo6beLCgS4udJamwQV6eaHsn9I/0J8fOUe4uEaIUEaCGEEKIb0FqzbOMx7l2+G093C1Xbc3j8U/D1dGNIdCCZxVXkldcBpi55YLSVeSN6kdIriJReQcSF+kpYFuIMSYAWQgghurgam4M/LN/FO5uzuLRfGE9dNwwFrE8vYu3hInZklXFJ79DGsDwo2oqXu9QlC3GuJEALIYQQF6jCyjre3nSM9UeKqa13UGt3UlfvwOHUWH08CPLxINDXg93Z5ezPq+COKf24c0q/xp7J04b0YNqQHp18FUJ0PxKghRBCiE50tKiajKIqgnw9CPLxJNDHg4P5Fbz+bSYf7cyl3qFJjArA6mMWHPEO8MKiFOW19Rwvr2Xf8QrcLIpXFo5gUmJEZ1+OEBcFCdBCCCHEeWZ3OPl8Xz7/+jaTrw8WtrpNgJc7N4yK44ZRsfSLDDjPIxRCnIoEaCGEEKIDaK05lF/Jhoxi8svrqLM7qa13UGNzsPpgAblltURZvbnr8v6MSgihotZOaU09ZTX1BPp4cMXQKHw95Z9pIS5E8l+mEEIIcY7Kaur5Yl8eJVX12J1O7E6Nze5kT045GzOKKamub9zW082Cl4cFbw83EqMCuHfmYC4bGIG7q8WcEKLrkAAthBBCnAWb3cmX+/N5b2s2n+/Nx+ZwnrRNXKgvUwZGMjIhhJHxIcSG+MqiI0J0IxKghRBCiGbsDieZxdUcOF7B/rwKDhdUUVJlo7TGRml1PUWVNmrqHYT5e3LDJbFcmRJDfKgfbm4Kd4vrS2aVhejWJEALIYQQQHphFS+sPsJ7W7OorTezykpBr2BfwgO8iAjwpn9EAEG+nlzaP4xL+4ZJUBbiIiUBWgghRLemtSazqJrtWWbp6tzyWuJDfekT7k/vcH8cTs0/1hzh413H8XCzcFVKDCMTQhgQFUCfcH98PGXBESFESxKghRBCdBtaa46X17L9WBk7skrZkWX+LK+1A+DlbiHS6s3KXcdxOHXjfgHe7vxsQh8Wjo0nIsC7s4YvhOgiJEALIYTokvYdL+fF1enszC6lqs5BZZ2dyjp7YzB2sygGRAbw/aQeJPUMIqlnIP0jA/Bws2CzOzlaXM2Rgkoqau1MHRxJgH2JXeYAACAASURBVLdHJ1+REKKrkAAthBCiy9BasyG9mL99dZhV+wvw9XRjbN8wrN4e+Hu54eflTkSAF0N7BjE42oq3R+vlF57uFvpG+NM3wv88X4EQojuQAC2EEKLTaK2xOzW19Q5q681CIzmlNWQWV3O0qJqjxdWUVNuoqLVTVWenvLaevPI6Qv08+eXl/blxdBxBvp6dfRlCiIuMBGghhBDnXY3NwavrMvj7V4dbLDbSnJtFERPkQ5i/JwHe7vQI9MbPy53kXkFcM7xnm7PLQgjR0SRACyGEOG/sDidvb8riqc8PkFdex4T+4aTFBePt4Ya3hwUvDzcird7EhfgSE+yDh7SJE0JcgCRACyGEaHdaa/bmVvDNoULyymspqrJRWFnHkYIqsktrSI0N4unrhjGqd2hnD1UIIc6aBGghhBDfmd3hpLDSxuGCSj7dk8ene/LILq0BwNvDQpi/F6H+XgzsYeXemYO4fFAkSsnS1kKIrkkCtBBCiDNSZ3eQX17HgbwK9h2v4EBeBUcKqjheXkthZR3a1VbZy93CuL5h3D65L5MHRkhfZSFEtyMBWgghRAv5FbWsOVjI1wcL2ZtbTllNPaXV9dTUO1psFxPkQ+9wPwb1sBJp9SIy0JvoIB9GJYTg6yn/vAghui/5P5wQQlzE6uwODuZVsiennN05ZWzIKGFvbjkAIX6eDOsVxNCYQAJ9PAjy9SDM34t+kQH0i/THKguPCCEuUhKghRDiIlNabeO/O3N5f2s2W4+WYnet3Ofn6UZSzyB+M20A4/uFM6iHFYtF6pSFEOJEEqCFEKIbKq228fKadAoq6/D3csfPyx1fTzc2Z5awal8BNoeTvhH+LLq0N0NirAyODiQuxFcCsxBCnAEJ0EII0Y3U1jt4dW0Gz646RGWdnRA/L6rq7I31y2H+Xtw4Oo6rhsUwONoqnTCEEOIcSIAWQoguzO5wcry8luySGg7kVfC3r46QXVrDpAHhLJ4+kAFRAQA4nJoqmx0/T3fcZJZZCCG+EwnQQghxAcoqqWbd4SLqHbrxOYezKSxnl9aQU1rL8fJaHM6mbYbEWHlkbhJj+oa1OJ6bRclNf0II0U4kQAshRCfYlV3G2sOFhPh5EWX1JtLqhVLw6Z58Pt6Vy46sslb3c7MooqzexAT7MDIhhJggH2KCfRr/TAj1kzpmIYToYBKghRDiPHE6NV/sy+elNUf49khxm9sl9wxk8fREpiRGYPVpmjVWCkJ8PXF3s5yP4QohhGiDBGghhOhA1TY7WzJL2ZBRzIc7cjhSUEV0oDd3XzGQK4fFUFVnJ6/clGLU2ByM6xdGz2Dfzh62EEKIU5AALYQQ35HWmoKKOo4UVpFTWtNYo7z3eAW7s8uwOzUWBSm9gnjquhSuGNoDD9cscniAF/Fhfp18BUIIIc6GBGghhDgLtfUODuVXsje3nH3HK9h3vJy9uRUUV9labBfm70nvMH9+MqE3IxNCSY0NIkBu4hNCiG5BArQQQpxCWU09Xx8sYNW+AnZklXKksKqx64W3h4UBkQFcPjCSxB4B9I3wJybIh+ggH7w93Dp55EIIITpKhwZopdQ04CnADXhJa/3QCa/HAq8CQa5tFmutP+rIMQkhxKlorTmYX8kX+/L5Yl8+mzNLcDg1Qb4epMUFM21IFIlRVhJ7BBAf6ic9lYUQ4iLUYQFaKeUGPAtcDmQBG5VSH2it9zTb7B7gba3180qpQcBHQHxHjUkIIU6ktSavvI6d2WWsPlDAF/vyyS6tAWBgDys/Gd+byYkRpPQKku4XQgghgI6dgR4JHNJaHwFQSi0DZgPNA7QGrK7vA4GcDhyPEOIiVW2z89HO45RW26itd1Bb76TKZudQfiW7c8ob65d9PNwY2zeMWyf1ZVJiOD0CfTp55EIIIS5EHRmgY4BjzR5nAaNO2GYJ8D+l1O2AH3BZB45HCHGRcTg172w+xuOfHiCvvK7xeaVMWO4d7sflAyMZFG1lULSVoTGBUrsshBDitDoyQLdWGKhPeDwf+KfW+jGl1GjgdaXUEK21s8WBlLoFuAUgNja2QwYrhOj6HE5NZZ2dqjo7u3PKeeSTfRzIqyQ1NoinrxvGwGgrXu4WPN0sKCW1y0IIIc5NRwboLKBXs8c9OblE40fANACt9TqllDcQBuQ330hr/QLwAkBaWtqJIVwIcRGx2Z1syihmU2ZJY7/l7NIa8sprqbY5WmwbH+rL8zekMm1IlARmIYQQ7aYjA/RGoJ9SKgHIBq4Drj9hm6PAFOCfSqmBgDdQ0IFjEkJ0MXaHk4yiarZklvDFvnzWHCqkss4OmEVIooN8GNTDyuTECAK83fH3Ml8hfp5MHBCBp7vc+CeEEKJ9dViA1lrblVK3AZ9gWtS9rLXerZS6H9iktf4A+CXwolLqF5jyjoVaa5lhFuIicyi/gq1HSxvLLyrq7OSV1bI/r5LD+ZXYHKaqK8rqzczkaCYnRjCmTyh+XtLKXgghxPmnulpeTUtL05s2bersYQgh2sGx4mqe+PQA723Lpvn/ijzdLIT5e9I/KoABkQH0jwxgcIyVAZEBUoohhBDivFFKbdZap534vEzfCCE6lMOp2XaslNJqG94ebnh7WHC3WHhvazZL12diUYpbxvdm/ohYAn088PNyl7ILIYQQFzQJ0EKIdmezO1l7uJBPdh/n0z15FFbaTtrGzaK4Nq0Xd07pR1SgdyeMUgghhDg3EqCFEO2iqs7OVwcK+GT3cb7Ym09FnR0/TzcmJkbwvcFRxIb4UlfvoNbupLbeQWJUAHGhfp09bCGEEOKsSYAWQpyTGpuDHVmlbD5awqaMEr45VEid3UmInyfTh0YxbUgUY/qEycIkQgghuh0J0EKIM1Znd7B8Ww5vrD/Kruwy7E5z51/vMD/mj4zle4OjGBEfjLub1DALIYToviRACyFOq6TKxr++zeTVdZkUVtaRGBXATyb0JjU2mGGxwYT4eXb2EIUQQojzRgK0EOIk+RW1bMksZevREjZnlrAjuwyb3cnEAeEsGtebsX1DpZ2cEEKIi5YEaCEEdoeTrcdK+WJfPqv25bPveAVg+jEPibGycEw8c4f3pH9kQCePVAghhOh8EqCFuAhV2+xsP1bGlqMlbMksYVNmCWU19bhbFGnxwSyensiI+BCGxFjxcpebAIUQQojmJEALcRHZlV3Gc18e4pPdeTgabgAM9+N7gyOZOCCCcf3CsHp7dPIohRBCiAubBGghLgKbM4v56xeHWLW/gAAvd24eE8/YvmEMiw0iyFduABRCCCHOhgRoIbohrTW7c8r53548Pt2Tx97ccoJ9PfjV1P7cODqeQB+ZZRZCCCHOlQRoIboBp1NzuKDSVdNcyppDhWSX1mBRMDwumHtnDmLeiF74esp/8kIIIcR3Jf+aCtHFOJya9MJKdueUsyennD255Ww/Vkp5rR2AIF8PRsSHcOdl/ZiSGEGov1cnj1gIIYToXiRAC9GFrD9SxG/e3UFmUTVg2sz1j/Ln+0k9SI0NJjUumN5hftKjWQghRNehNXSxf7ckQAvRBVTb7Dy8cj//XJtBbIgvD1+dxNCegfSN8MdDls0WQoizd/BTE9z6T+3skXQvWkNlHpRkQmkmlB6FyMHQf9rJITl7C6y4E4qPQNwYiL8UEsZD1FCwXNgtVCVAC3EB01qz9nARd7+3k4yian4wOo7fTk+UWmYhhDhXjnr4bAms+6t5PPVBGHN7pw7pJI562P4mfP04oE2oTJhgAmZA5On3Lcsy4bUkE2xVENQLguIgOA68A89uLFpDdTGUZpjjVRw3YTc6peV29jrY8hp8/RhU5J58nOhhMOke6DsF6mtg1R/h2+fALwKGzIGj38LB/5lt/SIgZT4MuxHC+p3deM8TpbXu7DGclbS0NL1p06bOHoYQHepAXgXLt2WzfFsOWSU19Az24eG5SYzpE9bZQxNCdCVaQ/5eyN8DfS8Dn6COP6fDDp/8DvauAGuMCW1BcSZwJc4Eyxl8alZTCvs/Bp9gCIo1x/D0++5jK8+Fd26Go+tg5C1QmQ973ofRt8HlD7Q+Nkc9HFgJW16HnK1gjW66puA4CIo3fwb2Ag9vsFWbWddSV9j0j2ja1sPXzLamfwXpq+HYBrNfwnjzFTMc9n0IX/7ZbBedCgE9IGMN1JWZ8Vhjmp07zszUNsz2lmRCeTZoR9vvgYcvqLOY3XXawV5z8vNRQ2HYTSb87v8IvnoYyo5B7BjzXMMYrdGwZzl8+RcoOwq9LoHK41CSAak/gMvvb/p7WZ5r3pc9y817rh0QO9oE6aFzwf3839OjlNqstU476XkJ0EJcGLJLa1ixPYfl23LYm1uORcG4fuHMTo5m+tAomXUW3Y/WJkjEDAevTlwmXmsoPNgUavL3Qo/kplATHN92faa9DjK+htB+Jiy0p/paE0hKMsFZD71GgW/I6ferLjbhteF6qgrM8/5R8P1HYeDM7zYuWzV8cDvYa2HaQ2Z2s/lr7/7IBKoBV5jZz9JMMyPqtEPcOJj1NIT2af3YdRXw7d9g7TNNgbGBX7h5Dxp+LuGJUFVo3v/01WYGMyCqaba2RzK4uZswXpppfq7/+wPYKmHWMyaQOR2wcjFseAGS5sHsZ81zDQE4/SvYvsy8h/5R0GeyKU9oKE1w2FqO0TsQak8Yd3Oe/ub8AAHREDfaBMmcraCdgAI0RA6FyXc3lT04HZC7venvZ0NYrsg12/tHnRDqG/6MBc8AE1xLMsw+lfln9eNGKROCG47pGwr7/gtbXzdjahAzHCbfA70ntf7fi90GW1+D1Y+aX4ZmPAkJl7Z93oo8Mwu/9XUz5l/uB0/fsxt7O5AALcQFprbewb7jFWw/Vsp/d+ayIb0YgGGxQcxOjub7SdGEB0gHDdFNFR02tY8ZX0PcWLjxvU6ZXWL7MvjsPqjIMY+tPSFqiAk0lXnmucDYptCWcKkJE8d3mX/Yd7wFNSWAgt4TzExZ4gwzE3ku6irgiz+aWdGTPgZX0CPJjCN2DIT0dgUkX3A6If1LM0u670MT7PyjzJgSxpsx/+//Qd5OGDgLrnj09KUArakuhjfmQdZGcPc2s5+XLYG0H0FtKbx5nZlVveIRGPnjpv0cdtj+BnxyjwneExebsgmLu3n/SjJMOPzmKagpNuF73F0miJVkmK+iw5D5jQmP0DKsegZA7CgozzGz7Q3PWSwtA21oP5j3OkQMbHpOa1N28MUD4GWFuvKm1yzuJsQOu9HM4Ls1m8hwOl0zqc1mf6vyzYxxQ9j0jzThuyTDBO6KXBP8e080P7+GoFlbBplrzS8B0SkwcPaZzdTb60zw9vA5/bYdIXcH7P3AhOfWapzbg9bm/QtJaP9jnwEJ0EJ0Aq01O7LKyCqpIa+8lrzyWnLKatmXW87hgkpcq2nTJ9yPK1NimJUSTVxoO3xMKcSFymGHb5+FVX8CN08zC7jpZUi6Dq762+n/Aa4qMjOTwQnf7R9re52Zedz0spnVTLneNdvsOq7WUHjAhLr0ryD9axMQwYSiyjwz/sTvw9Br4fgO2LrUzPR5B8GA6U2hO7Cn2a+xljTTBLXQPi2v4eCnsOLn5iP4QbMhYlDTbCLafIyfvhqOrW858+kXAcpiwpx3kJlJHbbAfMTe/PiOelj7tPko3cMbZj4Fg6868/es9Bj862ooSYerX4IeKfDhz+HwF+Zj+ZoS89qcF2Hwla0fo+I4fPQrM0PuH2VmqG0VTa/3mWzqZHsOb3scJRnm53FsvQlVCRPMWBrCbWW++cUsYw2gzCcIDe9jxMC2f1Hb9R9zLUGxTQE4rP+ZzfqLbksCtBDn2e6cMu77YA8bMoobn/N0txBl9aZ/pD+DogMZ1MPK4GgrPYN9pPWc6H6cThMsiw83zdIdXQ8Fe2HA9005gTXa1E6u+iNM/J2ZmWxL+tew7HozQ2jt2WxWeDwExpz5uEqPwts3mVnmsT+HyX9oObPY1rXk7TQBNnuLCd1J17YMV06nCdvb3oDDn0N1kXk+pDe4+5jrb/j4HsxH+A3jT//KzGaHDYDZf4VeI9seS32NmQEvzWyanbVVmtKMAd8//ex34SF47yeQvQkuuRUuvw/cmq1OWrDfBO36mqYg6RMMHy8255n/JsSPM9tqbT5mX/k7MxN63Run/li+wZ7lsPMdU3LRPKyGDzj9vkKcRxKghThPiqtsPPa//by54ShBvp784rJ+pMWHEGX1JsjXQ4KyuHDZbSb0+Ue2/vFxTampOW3Ozd0EQXfPpufKc2DbUtj6LxPuGviGmRnD0bfCoCubZke1huW3mn2u+jskX3fyuXe/D//5sZkhHvEj81F++tfm436A0L7NwnRsU7gszWwKsg0y1pia0iufh4EzzvZdOjNOp/lF4chX5nza2TQLGhRrPupPX22+qovA4gGX3gWX/vL8lLLYbfC/e2DD381NWtf80wTmLx+CnW+bwO8f3lS7DGbGeMG7psTlRNXFZlY8IKrjxy7EeSQBWogOUu9wsje3nC2ZJWw+WspX+/Opsjm4aXQcP5/Sn0Bfj9MfRFycTrd4QHsvLlBXaepWW5ttPfS5KR8oOwpuXk1trzx8mm6oauvmKGUxITo4ztSMZnxtAmP8pZByg6nbDYoDL/+2x2a3wb9crawmLjYf5fdINjW2G16Ej35tZmXnL2ua9XU6IX93UxDN+KZlOQCAT4j5haD5+xgQZWqA27qR7XxqCNqe/u1/E+KZ2PmOuSHQzdPMLlvcTe3y2J+DX5gpuanIMeUbEQOlnEFcdCRAC9HOymrqefrzg7yx/ig19aZlUJTVm5EJIdw2uS/9Izuxq4C4sJUehQ/vMh/bp94El/4KrD2aXs/bbWqE938EwxfCZfeBt/X0x7XXmaDT0K+14camhj9rik0ng2RXf9Xw/mbm8JO7zQ1eof0g7YfmRqeGfeprXDWhrlZi/lEmMDees8Z1TldXgppSUxc87AZTunA2akrgzevh6Frz2DsQIgabx/2nw9yXT30XvsNuyjKqCpo6EHRmd4+uIn8vfPgLiBwC438ls8hCNCMBWoh24nBq/r3pGI98sp/iahtXDYthcmIEqbHBRAd10p3QomtwOmHji6brA0C/y0w7KIs7jFhkyhrW/w12vWuCX++JpqOCfxTMeNzcmNac3QY5W0yZQPpqyNrQ8uYyN0/TY7axdKCXqd89sNJ8LN9rlOk1W1NiZhzH//rcu0e0p4q8lq3Jek+E7/3p9HXKQgjRziRAC/EdFVTUseZQAS+vyWBndhlpccEsmTWYITFnuaqTuPAUp5vuAgNnwJQlZ9Y+CkyALTvWNFt7qv6vYGaUj62HPlNgxhMm2JZkmK4IO5a52lH5wqifmhZfviGQtRk+uM205kqcYWaQG0oqGvvQutqbxV9qZhEbAnNAj9avpTLf3Pi17U2zgMEVj7Ze1yqEEBc5CdBCnIND+RX8e3MWXx8oZE+u6Q3aI9CbxdMTmZUcLTcEdgc1JfDS5SaQOmymJdnsZ1veFNegurhpZjT9a9PmjLP4f6hvqJlJTZp3cm1zwQFT0jFotlm5rDm7Db550vSq9fBp6loQHA89R5g+ylKbKoQQ7U4CtBBnoaymnqc+O8ir6zJQwPC4YMb3D2d8v3AGR1uxWCQ4dwsNN64dWw83LTcLGXzxgLmB7drXzU1vtWWmpGLrUsjeDGjw8IO4MRA9rGWPWd8QzEpibXD3MjfFnSun88xnx4UQQnxnbQVoKSgTopkT65vnj4zll5f3J9RfVgTsdrSGFXeYGeU5L5pAHDfGdGxYcSf88/um68Du982NchGDYNLvzaINMakt++aeLxKehRDigiABWgjAZneyYnsOf199mAN5lYyID+bVmSOlvrmjlOeaWd/mXSKCE0xAPbEUwWGHb58zC1NYezar741qOZvr7mPqeM+kh67dBqsfMXXAk+42C2I0SL3RtO/690KzdHDyPBh2kwnNUrIjhBACKeEQF7mqOjtvbjjKP9akk1tWS2JUALdO6suMpB5S33wunA44vAr2fmAWtBg69+RtMtfCm9c13XDnHWS6Q+TtMTXCVzzctMhG7g5zA13udggfaOqVK4+3fX53H4i9xJw7dnTLlmf1NXB0XVNnh/pqSL4ernyu9WBckWdKODxlaXUhhLhYSQmHECf4bE8ed7+/k7zyOkYlhPCnOUOZ2D9cgvO5KE43yxdvewPKs8yqalteNavFTXuoaVZ433/hnR9CYE+44R2zdK9PkHmtISz/e6FZjjisL6z9qwnV175mbq4DE4RLj0FlHi1u4Kspda1Otxo+v6/tsUYMMj2Qe0+A/tPanlUOiPyu74oQQohuSmagxUWnuMrGfSt2s3xbDolRATx45RDS4rtxBwNHven569GOPaorCyBjdVP/4ZJ0QEHfKSac9psKXz0E3zxlbrS79jU4/IVZrCF6GFz/b/ALbWWsdvj2WbOIiL0Whi2AqQ+CT/DZjy9nKzjrm56zuJtzn9jhQgghhGiDdOEQFz2b3ckH23P480d7Ka+t59ZJffm/iX3xdO9mN2alf21qextqi8uzAQUxw01pQ8J4syTy2QZqu830Md76uln2GQ1eVogfZ/oPD5plZpab27sC3v8/09/YVgl9L4drXz19WURJJlQVQs/hZzdGIYQQoh1JgBYXrYKKOt5Yf5Sl6zPJr6gjuWcgD89NZkDUBbjEr9aw422IHARRQ89+/4OfwbL54OlvyiMabrhz2k23iewtoB1mRveqF6D/1JOPUZ5jSjGar2hXXQy7/wPVRWCNgZTrzap4UcmnXx2u6DC891NzTVc82jndK4QQQohzIDXQ4qJTVWfnwf/u5d3NWdgcTiYOCOfhMfGM7xd+4fZxXvs0fPr/QLnB2Dtgwm/PfKb4yFfw1g0QPgB+sKL1sofaclev4wfhjWtg/G9g4mLTzcLphC3/hE/vhbrylvu5eZp64dSbTI/ks+llHNoHFn165tsLIYQQFzgJ0KJbOlJQyU//tZlD+ZXcMCqOhWPj6RPu39nDOrXd75vwPHCWKY1Y8wTs+QBmPQPxY0+9b+Y609kiOAFuXN52zbC3FQZMMzfQ/feXsPphyNpo2sd9dh9krjHlGLOehpDe7X+NQgghRDcgJRyi2/lk93F++fZ2PN0tPH3dMMb1C+vsIZ3esY3w6gyISoIffGBmnQ9/YRb0KD0KaT+Ey+4zAfhEmetg6TWmL/LNH535TXJam04ZH/3alGt4BcL3HjQ3AUonEiGEEEJqoEX3Z3c4eezTAzz/5WGSewby3ILhxAS1Y+eJjlKSAS9OMT2HF31uFvFoYKsyHSm+fQ78o2DG46b2GKBgP3z5Z9j9nllO+uaPwRp99ufP2Qq7/gOjbzUhXAghhBCABGjRzRVV1nHHsq18c6iI+SNjuXfmILw9zqJOt704naalW2ifM9s+bze8fZPpOLHoMwjr1/p2WZvhg9shfzcMnmP6Ku94Czx84ZKfwejbmvopCyGEEKJdyE2EotvadqyU//vXZgqrbDw8N4lr03p13MmOfgu73oWJvzt5yen6WnjvFtizHC79JUz+Q9ulEPY6s5T0mifMSnzz32w7PINp53bLl6av8uqHQVnMjPHYn7ecsRZCCCFEh5MALbosrTVvbjjGkg92Ex7gxX9+NoYhMYEdd8L6GvjPj01N8oGVZnGQ6GHmtdoyWHaDaRUXNxa+fsyslDfjqZPbvB1db2aTC/dD0nUw7c8nh/HWuHvChF+bThgWNwnOQgghRCeRAC26pLKaen7/3k7+uyOX8f3DeWpeCsF+nh170jVPmPD8vT/BuufgH9+DKx6B/t+Df82Fgr0w50UYeo2pTf7qL6Y0Y+4rZiGRPe/Dltfh2LcQ2AtueBf6XXb245AlpoUQQohO1aE10EqpacBTgBvwktb6oRNefwKY5HroC0RorU9ZyCk10GJzZjF3vLmN4+W13HV5f346oQ9uHd3XuTgdnh0FA2fA3Jehqgje/REcWWVazjkdMO91s5R1g43/MK3iQvtAxXGzEl9oP0i9EdJ+ZG4aFEIIIcQF67zXQCul3IBngcuBLGCjUuoDrfWehm201r9otv3twLCOGo/o+pxOzbOrDvHk5weJCfLhnZ+OZlhsG/2O29vK34HFHaY+aB77hcKCd80s8+734Kq/Q0xqy31G/Aj8ws2+g2ab9nCxl0iLOCGEEKKL68gSjpHAIa31EQCl1DJgNrCnje3nA/d24HhEF6a15r4Vu3l1XSZXpkTzwJVDCPA+T0tCH/gEDnxs+jA3bxNncTMLkEz6fdv7DpplvoQQQgjRbXRkgI4BjjV7nAWMam1DpVQckAB80cbrtwC3AMTGxrbvKMUFT2vNX1bu59V1mfxkfG8WT09EdcQsrtaQvRlKMyEoznx5BcDHv4Gw/nDJ/7X/OYUQQgjR5XRkgG4t4bRVcH0d8I7W2tHai1rrF4AXwNRAt8/wRFfx7KpD/O2rwyy4JPa7h+fiI1CSCcFx5kY+Nw+oLIAdy8wNfoX7W27v5mlW6bvxfdMFQwghhBAXvY4M0FlA84a8PYGcNra9Dri1A8ciuqh/rEnn0f8dYE5qDPfPGvLdwnP2FnjlCrDXmMfKAtYYqMgFpx16joRZz0B0KpQdM0G7NNOUbfSZdOpjCyGEEOKi0ZEBeiPQTymVAGRjQvL1J26klPr/7d15nJb1fe//12dmGPadYQcBRRTcRcCoAeMSTFwSY6M2aZamtemveSRdc5KmzTnNafs4p1vSnHpyahOTJo2lZjHBuGskLhEQQWSTRfZtGHaQdWa+vz/u22TEQWfgvuaae+b1fDzmwX1d98U1b65cZN5++d7fawLQH3ghwywqQ0+/uoP/+bPl3HDeUP7uQxdQcTorbezdCPfdDr1q4MavFlbFeKMg9xoCF30EBp/z6+OHnnf6fwBJktQhZVagU0r1EfEZ4DEKy9jdm1JaFhFfARakbTFdmgAAIABJREFUlGYXD70TmJXK7ZniytThYw385U+XMn5wL752x0VUVVac+smO7IPvf7jw9L+PP/jmoixJktRKmT5IJaX0MPDwCfu+fML2/8gyg8rTvzy9ms17DjPrrml0rao89RM1HIf7Pwa7VsNHf2x5liRJp+00hvWkbKzZcYB7nlnLrZeMYNq4gad+ol2vFR69vXYO3PR1GDe9ZBklSVLn5aO81a6klPiLnyyle5dK/vx957b+BMcOwfKfwqLvwYbnISrh6r+Aiz9S+rCSJKlTskCrXfnJy1uYu3Y3f/2B8xjUq2vrfvOap+DHd8GhnTBgHFzz3+HCO6HPsGzCSpKkTskCrXZj3+Hj/M1DK7hwVD9+c0orHpjT2AjP/gM8/bcw+Fz4je/AmCt9ZLYkScqEBVrtQmNj4k/uf5k9h47znU+e1/Il6w7tLow6r3kCLri9sERddc9sw0qSpE7NAq124R+fWMmTK3bwVzdP4rwRfVv2m/ZtgW/fAPu3wvv/ESZ/ylFnSZKUOQu0cjd78Vbufvo17pwyio9dfkbLftPRA3Dfhwsj0J98BEZdlm1ISZKkIgu0crVk8z4+/8PFXDamP3/V0kd1N9TDDz4BO1bAR35geZYkSW3KAq3c1B04yl3fW8DAnl35xkcvpbqqBcuSpwSP/BmseRJu+mc465rsg0qSJDVhgVZuvvrkKna9fowH/r93tXzJuhf+BRbcC1f8IVz6iUzzSZIkNccnESoXOw4c4Ycvbea2S0cyaXgLPzQ4/9/g8b+EiR8orPEsSZKUA0eglYt//+V6jjc08rtXjXvng1OCn/91Ya3ns2+AD/4/qPC//SRJUj4s0GpzB4/W870XNjBz0lDGDnqHNZsb6uFnf1h4NPfFvwU3fg0qvW0lSVJ+bCJqc7Pmb2T/kXo+Pf3MN7+x7hn44aeg12Dodwb0PwPqXoXXfg7v/jO4+kuu8yxJknJngVabOlbfyLeeW8e0cQO4cFS/N7/57D9CaoS+I2H3a4Xi3Hgc3vcPMOV38wksSZJ0Agu02tSDi7eybd8R/vbW89/8xo5XYe0cuObLcNWfFPalBA3HoKqFK3RIkiS1AT+JpTaTUuJfn3mNCUN6M+Psmje/Of9fobIrXPKJX++LsDxLkqR2xwKtNjNnZR2rag/ye9PHvfmJg4f3wOJZcMFvQM+B+QWUJElqAQu02kRKia//fDUj+nXnpguHv/nNhd+D44dg6qfzCSdJktQKFmi1iWdW72TRxr38wdVn0aWyyW3X2FB4QMoZV8LQ809+AkmSpHbCAq3MpZT46hOrGNGvO7ddOvLNb658BPZthKm/l084SZKkVrJAK3O/WFXHy5sKo8/VVSfccvP+H/QdDRPel084SZKkVnIZO2UqpcTXnizMff7w6/fB3/4f6DOi8JCUXkNg/bNw3Vd8uqAkSSobthZlak5x9PmbM45R9cz/gjPeBd37w94NsHEe9BhUeES3JElSmbBAKzNvjD6f3beRa1b8JfQfA795P3Tt9euDGhuhwplEkiSpfFiglZk5q+pYvGkvT4+bRWzbCr/92JvLM1ieJUlS2bG9KDPfePo1PtZ7AWO3/gymfx5GXZZ3JEmSpNPmCLQysXTLPjatX833ev0bjJgMV/1p3pEkSZJKwhFoZeLbz6/n811/SHU0wK33uMqGJEnqMCzQKrm6A0d5ZPFGZlYtJCZ+AAaemXckSZKkkrFAq+Tum7eRC9MKujccgHN8QIokSepYLNAqqWP1jfzHvA18cuAyqOoGZ74n70iSJEklZYFWST20ZCt1B47w7ob5MO5qqO6ZdyRJkqSSskCrZFJKfPv59Vw/YAfdDm11+oYkSeqQLNAqmYUb9/DK5n38wbCVQMDZN+QdSZIkqeQs0CqZ7/xyA326VXH+wedh1FToVZN3JEmSpJKzQKsk9h85zuPLtvOJiRVU1C5x+oYkSeqwLNAqiUeXbudofSMf7r2ksOOcG/MNJEmSlBELtEripy9v4YyBPRix42kYNMGHp0iSpA7LAq3Ttn3fEX752i5un9SLWP88nPP+vCNJkiRlxgKt0zZ78RZSgtv6roDUYIGWJEkdmgVap+2BRVu5aFQ/Bm9+AnoNheGX5B1JkiQpMxZonZZXt+9nxbb93HbBAFjzZGH0ucLbSpIkdVyZNp2ImBkRKyNiTUR84STHfDgilkfEsoi4L8s8Kr2fLNpKZUVwS68VcPwQnHtT3pEkSZIyVZXViSOiErgbuA7YDLwYEbNTSsubHDMe+CJwRUppT0QMziqPSq+xMfHTl7cw/ewaeq+9B7r3hzFX5h1LkiQpU1mOQE8B1qSU1qaUjgGzgFtOOOZ3gbtTSnsAUko7MsyjEpu3bjfb9h3h1gtqYNWjMOH9UNkl71iSJEmZyrJAjwA2NdneXNzX1NnA2RHxfETMjYiZGeZRif1k0RZ6VldyXfdX4eh+mHhz3pEkSZIyl9kUDiCa2Zea+f7jgRnASODZiDgvpbT3TSeKuAu4C2D06NGlT6pWO97QyKPLtnP9pKF0XfVNqO4N42bkHUuSJClzWY5AbwZGNdkeCWxt5pifppSOp5TWASspFOo3SSndk1KanFKaXFNTk1lgtdzctbvYd/g475s4CF59CM5+L1R1zTuWJElS5rIs0C8C4yNibERUA3cAs0845ifA1QARMYjClI61GWZSiTyydDs9qiuZ3m01HN7t9A1JktRpZFagU0r1wGeAx4AVwP0ppWUR8ZWIeKNtPQbsiojlwNPAn6WUdmWVSaXR0Jh4fFktV58zmOpVD0FVdzjr2rxjSZIktYks50CTUnoYePiEfV9u8joBf1z8Upl4acMedh48ysyJg+HJB+Gsa6C6Z96xJEmS2oSPjFOrPbJ0G9VVFVzTeyMc3A4TT1ydUJIkqeOyQKtVUko8tnQ77x5fQ481D0FFl8IHCCVJkjoJC7Ra5ZXN+9i67wgzJw2BFbMLS9d165t3LEmSpDZjgVarPLJ0O1UVwXsH1MLeja6+IUmSOh0LtFospcSjS7dx+ZkD6b3uYYjKwuO7JUmSOhELtFpsZe0B1u86xMzzhsKKB2HMFdBzYN6xJEmS2pQFWi32yJLtRMANQ/bBzlVwrtM3JElS52OBVos9unQ7l40ZwIANjxZ2nHNjvoEkSZJyYIFWi6yqPcDK2gO877yhsHw2jJoKfYblHUuSJKnNWaDVIj9bvJWKgJtGH4XaJXDuTXlHkiRJyoUFWu8opcSDrxRW3xi48bHCTgu0JEnqpCzQekfLtu5n3c7XuemC4YXpG8MuhP5j8o4lSZKUCwu03tHsxVvpUhnccEYjbFng6huSJKlTs0DrbTU2Jn62eCvvHl9D3/VvTN+wQEuSpM7LAq23tXDjHrbuO8JNFxanb9ScAzVn5x1LkiQpNxZova0HF2+la1UF140GNjzv6LMkSer0LNA6qfqGRh5aso1rzh1Mz9ceBhKcd2vesSRJknJlgdZJzVu3m50HjxVW31j6Y6g5Fwafm3csSZKkXFmgdVIPLt5Kz+pKrh5eDxtfgEkfzDuSJElS7izQalZ9QyOPLtvOdROH0G31Q0CCSR/IO5YkSVLuWlSgI+LMiOhafD0jIj4bEf2yjaY8vbxpL3sPHef6SUNh2QMweBLUTMg7liRJUu5aOgL9I6AhIs4CvgWMBe7LLJVyN2dlHZUVwZWDj8KmuXCe0zckSZKg5QW6MaVUD3wQ+FpK6Y+AYdnFUt7mrNrBpaP702ftQ4UdEy3QkiRJ0PICfTwi7gQ+DvysuK9LNpGUtx0HjrB0y36mT6gpTN8Yej4MOivvWJIkSe1CSwv0J4HLgb9JKa2LiLHAf2QXS3l6ZtVOAK4bfhQ2vwiTXPtZkiTpDVUtOSiltBz4LEBE9Ad6p5T+V5bBlJ85K3cwuHdXxu98qrDD1TckSZJ+paWrcMyJiD4RMQBYDHw7Iv4p22jKQ31DI8+u3sn0s2uIZQ/AsItgwLi8Y0mSJLUbLZ3C0TeltB+4Ffh2SulS4NrsYikvizfvZd/h41x/RgVsXQjn3pR3JEmSpHalpQW6KiKGAR/m1x8iVAf0xvJ1V1QuLew48z35BpIkSWpnWlqgvwI8BryWUnoxIsYBq7OLpbzMWVnHJaP70WPTs9C9Pwy7MO9IkiRJ7UqLCnRK6QcppQtSSr9f3F6bUvpQttHU1uoOHGXJln3MOLsG1s6Bse+Gisq8Y0mSJLUrLf0Q4ciIeCAidkREbUT8KCJGZh1ObeuZVXUAXDdkP+zfAuOuzjmRJElS+9PSKRzfBmYDw4ERwIPFfepA5qyqo6Z3V8YfXFDYMW5GnnEkSZLapZYW6JqU0rdTSvXFr+8ANRnmUhtraEw8u7qusHzd2jnQfwwMGJt3LEmSpHanpQV6Z0R8NCIqi18fBXZlGUxta1XtAfYeOs6V4/rCumcdfZYkSTqJlhbo36awhN12YBtwG4XHe6uDWLhxDwDTuq6HYwcs0JIkSSfR0lU4NqaUbk4p1aSUBqeUPkDhoSrqIBZu2MvAntUM2TkXCBg7Pe9IkiRJ7VJLR6Cb88clS6HcLdq4h4tH9y/Mfx52IfQYkHckSZKkdul0CnSULIVytef1Y6zd+TpTR3SBzS/CmS5fJ0mSdDKnU6BTyVIoV4s2FeY/X1W9Chrrnf8sSZL0Nqre7s2IOEDzRTmA7pkkUptbuGEvlRXBWQdehKpuMGpa3pEkSZLarbct0Cml3m0VRPl5acMeJg7rQ9X6Z2D05dClW96RJEmS2q3TmcKhDqC+oZHFm/dy9dAjULcCznxP3pEkSZLatbcdgVbHt7L2AIeONfBe5hd2nHtTvoEkSZLauUxHoCNiZkSsjIg1EfGFZt7/RETURcTLxa/fyTKP3mrhxr0AjK97EoZf7OO7JUmS3kFmBToiKoG7gRuAicCdETGxmUP/K6V0UfHrm1nlUfMWbdjDhT33UL1jMUzy2TiSJEnvJMsR6CnAmpTS2pTSMWAWcEuG30+nYOHGPXys76LCxqQP5BtGkiSpDGRZoEcAm5psby7uO9GHIuKViPhhRIzKMI9OsOvgUdbvOsS7jz0HIyZDv9F5R5IkSWr3sizQzT2p8MQ1pR8ExqSULgCeBP692RNF3BURCyJiQV1dXYljdl6LNu5lTGyj5uCrMOmDeceRJEkqC1kW6M1A0xHlkcDWpgeklHallI4WN/8NuLS5E6WU7kkpTU4pTa6pqckkbGe0cOMebqosrr7h9A1JkqQWybJAvwiMj4ixEVEN3AHMbnpARAxrsnkzsCLDPDrBwo17uLXrfBg1FfqOzDuOJElSWchsHeiUUn1EfAZ4DKgE7k0pLYuIrwALUkqzgc9GxM1APbAb+ERWefRm9Q2N7N+0nLGV62DS7+UdR5IkqWxk+iCVlNLDwMMn7Ptyk9dfBL6YZQY1b+nW/VzT+EtSZRATXRxFkiSppXyUdyf1i5V13Fg5l/qRU6HP8LzjSJIklQ0LdCe1avkiJlRspsv5PjxFkiSpNSzQndDeQ8foX/tCYeOsa/MNI0mSVGYs0J3Qc2t2Mq1iGcd6DocB4/KOI0mSVFYs0J3QM6/W8q7K5VSdOR2iuefdSJIk6WQyXYVD7U9Kia2rXmIAB2Dc9LzjSJIklR1HoDuZlbUHmHB4UWFj7FX5hpEkSSpDFuhO5hcr67i8Yhn1/cb59EFJkqRTYIHuZJ5duZ3LK18tzH+WJElSq1mgO5HXj9ZzZONL9OSw858lSZJOkQW6E3nhtV1MSUsLG2Oc/yxJknQqLNCdyC9W1XFl1XIaB0+CnoPyjiNJklSWLNCdREqJX67czOSKlVQ4fUOSJOmUWaA7iQ27DlGzbwnV6RiMfXfecSRJksqWBbqTeGHtLi6vWEaKCjjjXXnHkSRJKlsW6E5i/rrdTK9aAcMvgW59844jSZJUtizQncSStVs4n9WE0zckSZJOiwW6E9i0+xBDDyyhkgYYc2XecSRJksqaBboTmL9uN5fEahIBIy/LO44kSVJZs0B3AvPX7WZKlzUw+Fzo1ifvOJIkSWXNAt0JzF9bx8UVawhHnyVJkk6bBbqDq91/hIo9r9Gz8SCMmpJ3HEmSpLJnge7g5q/bzSUVqwsbjkBLkiSdNgt0Bzdv3S6mVL1G6tYXBo7PO44kSVLZs0B3cPPX7WZq9drC/OcK/+eWJEk6XTaqDmz368fYWruDUcfXw0jnP0uSJJWCBboDm79uNxdWvEaQYOTkvONIkiR1CBboDmz+ut1MqVxTfICKBVqSJKkULNAd2Pz1u7iqx3qi5hzo1jfvOJIkSR2CBbqD2n/kOMu37uPchlWOPkuSJJWQBbqDemnDHsawje71+3yAiiRJUglZoDuoRRv2cOmvHqBigZYkSSoVC3QHtWjTXmb03ABd+8Kgs/OOI0mS1GFYoDugxsbEy5v2Fh7hPfJSH6AiSZJUQjarDmjtzoM0HjnAkCPrnL4hSZJUYhboDmjhxr1cVLGGChph1GV5x5EkSepQLNAd0Mub9jKzejGpqhuMvjzvOJIkSR2KBboDWrRhDzMrXyLGzYDqnjmnkSRJ6lgs0B3M60friR1LqWmohQnvyzuOJElSh2OB7mBe2byPa+MlEgETbsg7jiRJUodjge5gXt60l+srF9AwfDL0Gpx3HEmSpA7HAt3BbFj7KudVrKdq0k15R5EkSeqQLNAdSEqJgZufKmxMeH++YSRJkjooC3QHsmXvYS4/Ppe9PcfCoLPyjiNJktQhZVqgI2JmRKyMiDUR8YW3Oe62iEgRMTnLPB3dstc2MK1iBcfO8sODkiRJWcmsQEdEJXA3cAMwEbgzIiY2c1xv4LPAvKyydBaHlj1KVTQy4JIP5B1FkiSpw8pyBHoKsCaltDaldAyYBdzSzHH/E/g74EiGWTqFwVufZE9Ff6p8fLckSVJmsizQI4BNTbY3F/f9SkRcDIxKKf3s7U4UEXdFxIKIWFBXV1f6pB3AsSOHufDIAtYPnA4VTm2XJEnKSpZNK5rZl371ZkQF8FXgT97pRCmle1JKk1NKk2tqakoYsePYvOgxesUR6sc7/1mSJClLWRbozcCoJtsjga1NtnsD5wFzImI9MA2Y7QcJT83OVXMBGH3JdTknkSRJ6tiyLNAvAuMjYmxEVAN3ALPfeDOltC+lNCilNCalNAaYC9ycUlqQYaYO6+iWZWyvGMKQQQPzjiJJktShZVagU0r1wGeAx4AVwP0ppWUR8ZWIuDmr79sZbd5ziEFH1nG0//i8o0iSJHV4VVmePKX0MPDwCfu+fJJjZ2SZpSN77JXNfDS2ceSMG/OOIkmS1OG5XEMHsHDxIrpGPX1HX5B3FEmSpA7PAl3mtu07TP32FYWNmgn5hpEkSeoELNBl7tGl2zkrthQ2Bp2dbxhJkqROwAJd5h5Zsp1Le9RC31HQtXfecSRJkjo8C3QZ27H/CC9u2M151dug5py840iSJHUKFugy9uiy7URqZNCRDc5/liRJaiMW6DL28JJtXDXoIBUNRx2BliRJaiMW6DJVd+Ao89ft5oMjDxZ2WKAlSZLahAW6TD2xvJbGBO/qu7OwwykckiRJbcICXaaef20nw/p2o+bwOugzArr1yTuSJElSp2CBLkMpJeat3c3UsQOIulcdfZYkSWpDFugytHbn6+w8eJSpY/tD3SrnP0uSJLUhC3QZmrd2NwBXDDoE9Yct0JIkSW3IAl2G5q7dRU3vroyq31jYYYGWJElqMxboMpNSYt66XUwbN7Aw/xmg5ux8Q0mSJHUiFugys2HXIWr3H2Xq2AFQtxJ6DYXu/fOOJUmS1GlYoMvMvHW7AJg2bgDUvQqDnb4hSZLUlizQZWbe2t0M6lXNmYN6Fkagnf8sSZLUpizQZWbeut1MGTuA2L8Zjr/uGtCSJEltzAJdRjbtPsSWvYeZOnZgYfQZHIGWJElqYxboMjJvXWH956njBsC2xYWdFmhJkqQ2ZYEuI/PW7qJfjy6cPbg3LHsARlwKPQbkHUuSJKlTsUCXkXnrdjNlzAAqapdA7VK48M68I0mSJHU6FugysXXvYTbuPsTUcQNh8Syo6ALnfSjvWJIkSZ2OBbpMvLH+89QzesOS+2HCTKdvSJIk5cACXSaeWF5Lvx5dOPf1BfB6ndM3JEmScmKBLgNb9h7msWW13D55FJWv/Cf0GAhnXZd3LEmSpE7JAl0GvvvCelJKfOzivrDyETjvNqiqzjuWJElSp2SBbucOHatn1vxNvHfSUEZseRQajsJFTt+QJEnKiwW6nXtg0Rb2HT7OJ68YW1h9o+YcGHZR3rEkSZI6LQt0O5ZS4jvPr2fS8D5c1ns3bJpX+PBgRN7RJEmSOi0LdDv23JqdrN5xkN++Yiyx5AcQFXDB7XnHkiRJ6tQs0O3Yt59fz6BeXbnxwmGw6hEYOQX6DMs7liRJUqdmgW6n1u18nZ+/uoOPTB1N18M7YdtiGO/SdZIkSXmzQLdT33thA10qg49MGw1rnizsHH99vqEkSZJkgW6PUko8snQbMyYMZnDvbrDmCeg1FIaen3c0SZKkTs8C3Q4t3bKfbfuO8N5JQ6GhHl77OYy/1tU3JEmS2gELdDv0+PLtVARcc85g2PwiHNnno7slSZLaCQt0O/TE8louGzOA/j2rYfXjEJVw5tV5x5IkSRIW6HZn465DvLr9ANdPGlrYseYJGD0NuvXNN5gkSZIAC3S78/jy7QBcP3EI7N8G25fAWdfmnEqSJElvsEC3M48vr+Wcob0ZNaCHy9dJkiS1QxbodmT368dYsH73r6dvrH4ceg+HIZPyDSZJkqRfybRAR8TMiFgZEWsi4gvNvP/piFgSES9HxHMRMTHLPO3dUytqaUzF6RsNx2HtHJevkyRJamcyK9ARUQncDdwATATubKYg35dSOj+ldBHwd8A/ZZWnHDy+vJbhfbsxaXgf2DQPju53+TpJkqR2JssR6CnAmpTS2pTSMWAWcEvTA1JK+5ts9gRShnnatcPHGnh2dR3XTxpKHNoNc78BFVUwbkbe0SRJktREVYbnHgFsarK9GZh64kER8QfAHwPVwHsyzNOuPbu6jurjB/jU8fvgn78Dx16HK/8IuvXJO5okSZKayLJANzdx9y0jzCmlu4G7I+I3gb8APv6WE0XcBdwFMHr06BLHbB9qf3kfz3X7B/oseR0mfgBmfBEGn5N3LEmSJJ0gywK9GRjVZHsksPVtjp8FfKO5N1JK9wD3AEyePLnDTfM4cvQYN2z5Gvu7DafPx++FYRfkHUmSJEknkeUc6BeB8RExNiKqgTuA2U0PiIjxTTbfD6zOME+7teS5BxnEPvZf9jnLsyRJUjuX2Qh0Sqk+Ij4DPAZUAvemlJZFxFeABSml2cBnIuJa4Diwh2amb3QGx16+n4P04Owrbs07iiRJkt5BllM4SCk9DDx8wr4vN3n9uSy/fznYd+AAF+z/BasHXc3F3XrmHUeSJEnvwCcR5mzp0/fTOw7T57KP5B1FkiRJLWCBzlnV8h+xO/ox7rKZeUeRJElSC1igc1RbW8tFh+ezfuhMojLT2TSSJEkqEQt0jl59+j66xnGGXPlbeUeRJElSC1mgc9R3zQNsrRjOiIlX5B1FkiRJLWSBzsm6dWu44Pgr1J5xI0RzD22UJElSe2SBzsm6X/wHFZEYPf1jeUeRJElSK1igc9DYmBi24UHWdzmLgWPOzzuOJEmSWsECnYOFL73AuWkNB8+5Le8okiRJaiULdA52//K71FPB+Gs+kXcUSZIktZIFuo3t2n+IC3Y/xtq+l9O137C840iSJKmVLNBtbN7Pf8LQ2E3vqa79LEmSVI4s0G0opUSXpf/FwejFsMs+mHccSZIknQILdBtauGYTVxx/gdpRN0CXbnnHkSRJ0imwQLehVU9/nx5xlBEzPpV3FEmSJJ0iC3Qb2Xf4OOO2zGZn9Ui6jZ2WdxxJkiSdIgt0G3nqhReZGsupP/8OH90tSZJUxizQbeTgi98HYMiVPrpbkiSpnFmg28CKrfu48vUn2dZ/MtH/jLzjSJIk6TRYoNvA/GcfY1zFdnpPc/RZkiSp3FmgM9bQmOi98gccjW70uujWvONIkiTpNFmgM/bLlVu4puE5do66Hrr2zjuOJEmSTpMFOmNrnv0BfeMQNVd8PO8okiRJKgELdIYOHq1nzJbZ7OtSQ/X4q/OOI0mSpBKwQGfo6ZeWchUvc+ic26CiMu84kiRJKgELdIb2zLuPqmhk6FWfyDuKJEmSSsQCnZGtew9z6Z5H2d5rIjH4nLzjSJIkqUQs0Bl59rk5TKrYQPUlv5l3FEmSJJWQBToDKSXilVkcp4oBUy3QkiRJHYkFOgOv1e5nxtE5bBt8FfQcmHccSZIklZAFOgNL5z3J4NhLr0tvzzuKJEmSSswCnYFY9XBh+saF7887iiRJkkrMAl1iuw8e5YIDz7Gl32To1ifvOJIkSSoxC3SJLVgwl7EV26maeGPeUSRJkpQBC3SJHXplNgDDp9yacxJJkiRlwQJdQkfrGxi7aw6bup9LRb8ReceRJElSBizQJbRw6QoujDUcO2tm3lEkSZKUEQt0CdW99BMARl5+W85JJEmSlBULdImklKjZ/CQ7qobTddikvONIkiQpIxboElm5YSuXNC5hz6hrISLvOJIkScqIBbpE1s39KV2jniFTnL4hSZLUkVmgS6THusfYF33oN+HKvKNIkiQpQxboEtiyax8XH5nP1iEzoKIy7ziSJEnKkAW6BF55ahZ94hCDpnw47yiSJEnKWKYFOiJmRsTKiFgTEV9o5v0/jojlEfFKRDwVEWdkmScLKSUGrPwvdlUMouai9+UdR5IkSRnLrEBHRCVwN3ADMBG4MyImnnDYImBySukC4IfA32WVJytLVyznsvqF1I77kNM3JEmSOoEsR6CnAGtSSmtTSseAWcAtTQ9IKT2dUjpU3JwLjMwwTyZqn7mTUHK3AAAK1UlEQVSXikiMvvZ3844iSZKkNpBlgR4BbGqyvbm472Q+BTySYZ6SO3LsOOdu/ymrelxCr6Hj844jSZKkNpBlgW7uaSKp2QMjPgpMBv7+JO/fFRELImJBXV1dCSOenpefeZAR1NF48W/lHUWSJEltJMsCvRkY1WR7JLD1xIMi4lrgS8DNKaWjzZ0opXRPSmlySmlyTU1NJmFPRSz6Lvvoxfjpd+YdRZIkSW0kywL9IjA+IsZGRDVwBzC76QERcTHwrxTK844Ms5Tczh3buejgc6wZcgOV1d3zjiNJkqQ2klmBTinVA58BHgNWAPenlJZFxFci4ubiYX8P9AJ+EBEvR8Tsk5yu3Vn15LfoGsepmf47eUeRJElSG6rK8uQppYeBh0/Y9+Umr6/N8vtnJiWGvnY/a6rO4qyJ0/JOI0mSpDbkkwhPwcZlLzCuYT07x9+edxRJkiS1MQv0Kdg/97scTV0YM8PVNyRJkjobC3RrNRxn9NaHmVc9haFDhuWdRpIkSW3MAt1KR1Y8Sp/GfWwf88G8o0iSJCkHmX6IsCPaP/d7HEx9GHnZjXlHkSRJUg4cgW6NQ7sZsOXnPMSVXDpucN5pJEmSlAMLdCukpT+iKh1n/Yib6FpVmXccSZIk5cApHK1w9KX7WNc4inHnXZ53FEmSJOXEEeiW2rmabrUL+XHDVUyfMCTvNJIkScqJBbqlFv8njVSwsO91jB7YI+80kiRJyokFuiUaG0mLZ/FcOp/zz5mQdxpJkiTlyALdEuufJfZv4QfHr2L6hJq800iSJClHFuiWGH4xs8f8OXMqpjBt7MC800iSJClHrsLREt368PXd07hobDe6V7t8nSRJUmfmCHQLbN5ziDU7DjL9bKdvSJIkdXYW6BbYefAYk4b3YYbznyVJkjo9p3C0wEWj+vHQZ6/KO4YkSZLaAUegJUmSpFawQEuSJEmtYIGWJEmSWsECLUmSJLWCBVqSJElqBQu0JEmS1AoWaEmSJKkVLNCSJElSK1igJUmSpFawQEuSJEmtYIGWJEmSWsECLUmSJLWCBVqSJElqBQu0JEmS1AoWaEmSJKkVLNCSJElSK1igJUmSpFawQEuSJEmtECmlvDO0SkTUARva4FsNAna2wffp6LyOpeF1LA2v4+nzGpaG17E0vI6nz2v49s5IKdWcuLPsCnRbiYgFKaXJeecod17H0vA6lobX8fR5DUvD61gaXsfT5zU8NU7hkCRJklrBAi1JkiS1ggX65O7JO0AH4XUsDa9jaXgdT5/XsDS8jqXhdTx9XsNT4BxoSZIkqRUcgZYkSZJawQLdjIiYGRErI2JNRHwh7zzlIiJGRcTTEbEiIpZFxOeK+wdExBMRsbr4a/+8s7Z3EVEZEYsi4mfF7bERMa94Df8rIqrzztjeRUS/iPhhRLxavCcv915svYj4o+Lf56UR8Z8R0c378Z1FxL0RsSMiljbZ1+z9FwVfL/7MeSUiLskveftxkmv498W/069ExAMR0a/Je18sXsOVEfHefFK3P81dxybv/WlEpIgYVNz2XmwhC/QJIqISuBu4AZgI3BkRE/NNVTbqgT9JKZ0LTAP+oHjtvgA8lVIaDzxV3Nbb+xywosn2/wa+WryGe4BP5ZKqvPwz8GhK6RzgQgrX03uxFSJiBPBZYHJK6TygErgD78eW+A4w84R9J7v/bgDGF7/uAr7RRhnbu+/w1mv4BHBeSukCYBXwRYDiz5o7gEnF3/N/iz/P1fx1JCJGAdcBG5vs9l5sIQv0W00B1qSU1qaUjgGzgFtyzlQWUkrbUkoLi68PUCgsIyhcv38vHvbvwAfySVgeImIk8H7gm8XtAN4D/LB4iNfwHUREH+DdwLcAUkrHUkp78V48FVVA94ioAnoA2/B+fEcppWeA3SfsPtn9dwvw3VQwF+gXEcPaJmn71dw1TCk9nlKqL27OBUYWX98CzEopHU0prQPWUPh53umd5F4E+CrweaDph+G8F1vIAv1WI4BNTbY3F/epFSJiDHAxMA8YklLaBoWSDQzOL1lZ+BqF/1NrLG4PBPY2+aHhPfnOxgF1wLeLU2G+GRE98V5slZTSFuAfKIxQbQP2AS/h/XiqTnb/+XPn1Pw28EjxtdewFSLiZmBLSmnxCW95HVvIAv1W0cw+lypphYjoBfwI+MOU0v6885STiLgR2JFSeqnp7mYO9Z58e1XAJcA3UkoXA6/jdI1WK87RvQUYCwwHelL4J94TeT+eHv+Ot1JEfInCtMHvv7GrmcO8hs2IiB7Al4AvN/d2M/u8js2wQL/VZmBUk+2RwNacspSdiOhCoTx/P6X04+Lu2jf+Caj464688pWBK4CbI2I9helD76EwIt2v+E/o4D3ZEpuBzSmlecXtH1Io1N6LrXMtsC6lVJdSOg78GHgX3o+n6mT3nz93WiEiPg7cCHwk/XotXq9hy51J4T+KFxd/1owEFkbEULyOLWaBfqsXgfHFT5lXU/hQwuycM5WF4lzdbwErUkr/1OSt2cDHi68/Dvy0rbOVi5TSF1NKI1NKYyjcez9PKX0EeBq4rXiY1/AdpJS2A5siYkJx1zXAcrwXW2sjMC0iehT/fr9xHb0fT83J7r/ZwMeKKyBMA/a9MdVDbxYRM4H/BtycUjrU5K3ZwB0R0TUixlL4ENz8PDK2dymlJSmlwSmlMcWfNZuBS4r/v+m92EI+SKUZEfE+CqN+lcC9KaW/yTlSWYiIK4FngSX8ev7un1OYB30/MJrCD+TfSCk194EGNRERM4A/TSndGBHjKIxIDwAWAR9NKR3NM197FxEXUfggZjWwFvgkhUED78VWiIi/Am6n8M/li4DfoTAn0vvxbUTEfwIzgEFALfDfgZ/QzP1X/I+Tf6GwUsIh4JMppQV55G5PTnINvwh0BXYVD5ubUvp08fgvUZgXXU9hCuEjJ56zM2ruOqaUvtXk/fUUVtrZ6b3YchZoSZIkqRWcwiFJkiS1ggVakiRJagULtCRJktQKFmhJkiSpFSzQkiRJUitYoCWpnYuIhoh4uclXyZ6qGBFjImJpqc4nSZ1B1TsfIknK2eGU0kV5h5AkFTgCLUllKiLWR8T/joj5xa+zivvPiIinIuKV4q+ji/uHRMQDEbG4+PWu4qkqI+LfImJZRDweEd2Lx382IpYXzzMrpz+mJLU7FmhJav+6nzCF4/Ym7+1PKU2h8PSwrxX3/Qvw3ZTSBcD3ga8X938d+EVK6ULgEmBZcf944O6U0iRgL/Ch4v4vABcXz/PprP5wklRufBKhJLVzEXEwpdSrmf3rgfeklNZGRBdge0ppYETsBIallI4X929LKQ2KiDpgZNPHbkfEGOCJlNL44vZ/A7qklP46Ih4FDlJ4BPVPUkoHM/6jSlJZcARakspbOsnrkx3TnKNNXjfw68/HvB+4G7gUeCki/NyMJGGBlqRyd3uTX18ovv4lcEfx9UeA54qvnwJ+HyAiKiOiz8lOGhEVwKiU0tPA54F+wFtGwSWpM3I0QZLav+4R8XKT7UdTSm8sZdc1IuZRGBC5s7jvs8C9EfFnQB3wyeL+zwH3RMSnKIw0/z6w7STfsxL4j4joCwTw1ZTS3pL9iSSpjDkHWpLKVHEO9OSU0s68s0hSZ+IUDkmSJKkVHIGWJEmSWsERaEmSJKkVLNCSJElSK1igJUmSpFawQEuSJEmtYIGWJEmSWsECLUmSJLXC/w/OQzysjDTpbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = baseline_model_val_dict['accuracy'] \n",
    "val_acc_values = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "ax.plot(epochs, acc_values, label='Training accuracy')\n",
    "ax.plot(epochs, val_acc_values, label='Validation accuracy')\n",
    "ax.set_title('Training & validation accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=10), \n",
    "                  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.9436 - accuracy: 0.1512 - val_loss: 1.9335 - val_accuracy: 0.1680\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9277 - accuracy: 0.1709 - val_loss: 1.9203 - val_accuracy: 0.1780\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.9125 - accuracy: 0.1919 - val_loss: 1.9072 - val_accuracy: 0.1910\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8972 - accuracy: 0.2081 - val_loss: 1.8948 - val_accuracy: 0.2050\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8820 - accuracy: 0.2228 - val_loss: 1.8818 - val_accuracy: 0.2050\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8657 - accuracy: 0.2336 - val_loss: 1.8671 - val_accuracy: 0.2150\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.8477 - accuracy: 0.2477 - val_loss: 1.8493 - val_accuracy: 0.2360\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8268 - accuracy: 0.2685 - val_loss: 1.8286 - val_accuracy: 0.2530\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8029 - accuracy: 0.2901 - val_loss: 1.8036 - val_accuracy: 0.2790\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7750 - accuracy: 0.3241 - val_loss: 1.7752 - val_accuracy: 0.3050\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7426 - accuracy: 0.3525 - val_loss: 1.7426 - val_accuracy: 0.3390\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7066 - accuracy: 0.3820 - val_loss: 1.7076 - val_accuracy: 0.3600\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6679 - accuracy: 0.4075 - val_loss: 1.6681 - val_accuracy: 0.3920\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6272 - accuracy: 0.4337 - val_loss: 1.6285 - val_accuracy: 0.4180\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5850 - accuracy: 0.4675 - val_loss: 1.5887 - val_accuracy: 0.4410\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5415 - accuracy: 0.4924 - val_loss: 1.5463 - val_accuracy: 0.4640\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4971 - accuracy: 0.5184 - val_loss: 1.5033 - val_accuracy: 0.4900\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4523 - accuracy: 0.5457 - val_loss: 1.4597 - val_accuracy: 0.5210\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4071 - accuracy: 0.5643 - val_loss: 1.4167 - val_accuracy: 0.5520\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3617 - accuracy: 0.5895 - val_loss: 1.3751 - val_accuracy: 0.5630\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3168 - accuracy: 0.6035 - val_loss: 1.3297 - val_accuracy: 0.5930\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2723 - accuracy: 0.6255 - val_loss: 1.2917 - val_accuracy: 0.6000\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2293 - accuracy: 0.6400 - val_loss: 1.2492 - val_accuracy: 0.6150\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1872 - accuracy: 0.6536 - val_loss: 1.2112 - val_accuracy: 0.6240\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1473 - accuracy: 0.6640 - val_loss: 1.1700 - val_accuracy: 0.6300\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1093 - accuracy: 0.6733 - val_loss: 1.1363 - val_accuracy: 0.6430\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0732 - accuracy: 0.6791 - val_loss: 1.1055 - val_accuracy: 0.6520\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0392 - accuracy: 0.6884 - val_loss: 1.0733 - val_accuracy: 0.6570\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0073 - accuracy: 0.6936 - val_loss: 1.0420 - val_accuracy: 0.6580\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9774 - accuracy: 0.7025 - val_loss: 1.0182 - val_accuracy: 0.6660\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9497 - accuracy: 0.7079 - val_loss: 0.9898 - val_accuracy: 0.6610\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9242 - accuracy: 0.7147 - val_loss: 0.9670 - val_accuracy: 0.6710\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9000 - accuracy: 0.7203 - val_loss: 0.9463 - val_accuracy: 0.6750\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8782 - accuracy: 0.7236 - val_loss: 0.9258 - val_accuracy: 0.6790\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8573 - accuracy: 0.7295 - val_loss: 0.9118 - val_accuracy: 0.6800\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8381 - accuracy: 0.7324 - val_loss: 0.8935 - val_accuracy: 0.6910\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8203 - accuracy: 0.7353 - val_loss: 0.8777 - val_accuracy: 0.6900\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8037 - accuracy: 0.7401 - val_loss: 0.8660 - val_accuracy: 0.6890\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7879 - accuracy: 0.7444 - val_loss: 0.8571 - val_accuracy: 0.6940\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7734 - accuracy: 0.7472 - val_loss: 0.8395 - val_accuracy: 0.7000\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.7599 - accuracy: 0.7511 - val_loss: 0.8292 - val_accuracy: 0.7040\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.7466 - accuracy: 0.7552 - val_loss: 0.8214 - val_accuracy: 0.7090\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.7342 - accuracy: 0.7580 - val_loss: 0.8111 - val_accuracy: 0.7090\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.7226 - accuracy: 0.7609 - val_loss: 0.8023 - val_accuracy: 0.7110\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7118 - accuracy: 0.7636 - val_loss: 0.7933 - val_accuracy: 0.7090\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.7012 - accuracy: 0.7663 - val_loss: 0.7850 - val_accuracy: 0.7090\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6912 - accuracy: 0.7705 - val_loss: 0.7785 - val_accuracy: 0.7130\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.6813 - accuracy: 0.7719 - val_loss: 0.7755 - val_accuracy: 0.7110\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6730 - accuracy: 0.7739 - val_loss: 0.7665 - val_accuracy: 0.7150\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6639 - accuracy: 0.7763 - val_loss: 0.7611 - val_accuracy: 0.7120\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.6558 - accuracy: 0.7789 - val_loss: 0.7546 - val_accuracy: 0.7180\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.6478 - accuracy: 0.7819 - val_loss: 0.7505 - val_accuracy: 0.7190\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6398 - accuracy: 0.7849 - val_loss: 0.7479 - val_accuracy: 0.7210\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6325 - accuracy: 0.7863 - val_loss: 0.7391 - val_accuracy: 0.7200\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6252 - accuracy: 0.7888 - val_loss: 0.7322 - val_accuracy: 0.7210\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.6181 - accuracy: 0.7924 - val_loss: 0.7351 - val_accuracy: 0.7270\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6112 - accuracy: 0.7959 - val_loss: 0.7247 - val_accuracy: 0.7260\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.6048 - accuracy: 0.7980 - val_loss: 0.7244 - val_accuracy: 0.7260\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5982 - accuracy: 0.7992 - val_loss: 0.7223 - val_accuracy: 0.7230\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5921 - accuracy: 0.8029 - val_loss: 0.7196 - val_accuracy: 0.7280\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5866 - accuracy: 0.8023 - val_loss: 0.7116 - val_accuracy: 0.7290\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5805 - accuracy: 0.8055 - val_loss: 0.7080 - val_accuracy: 0.7280\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5742 - accuracy: 0.8080 - val_loss: 0.7071 - val_accuracy: 0.7300\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5684 - accuracy: 0.8109 - val_loss: 0.7058 - val_accuracy: 0.7330\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5634 - accuracy: 0.8116 - val_loss: 0.6995 - val_accuracy: 0.7310\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5580 - accuracy: 0.8152 - val_loss: 0.6955 - val_accuracy: 0.7310\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5525 - accuracy: 0.8179 - val_loss: 0.7046 - val_accuracy: 0.7300\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5476 - accuracy: 0.8191 - val_loss: 0.6969 - val_accuracy: 0.7260\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5423 - accuracy: 0.8209 - val_loss: 0.6979 - val_accuracy: 0.7290\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5375 - accuracy: 0.8229 - val_loss: 0.6913 - val_accuracy: 0.7300\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5323 - accuracy: 0.8228 - val_loss: 0.6908 - val_accuracy: 0.7280\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.5275 - accuracy: 0.8271 - val_loss: 0.6888 - val_accuracy: 0.7320\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5226 - accuracy: 0.8271 - val_loss: 0.6816 - val_accuracy: 0.7310\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5185 - accuracy: 0.8307 - val_loss: 0.6852 - val_accuracy: 0.7330\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5140 - accuracy: 0.8305 - val_loss: 0.6871 - val_accuracy: 0.7310\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5090 - accuracy: 0.8325 - val_loss: 0.6923 - val_accuracy: 0.7340\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5054 - accuracy: 0.8344 - val_loss: 0.6814 - val_accuracy: 0.7330\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.5008 - accuracy: 0.8359 - val_loss: 0.6843 - val_accuracy: 0.7420\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4965 - accuracy: 0.8348 - val_loss: 0.6774 - val_accuracy: 0.7330\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4922 - accuracy: 0.8399 - val_loss: 0.6772 - val_accuracy: 0.7330\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4879 - accuracy: 0.8399 - val_loss: 0.6742 - val_accuracy: 0.7360\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.4844 - accuracy: 0.8432 - val_loss: 0.6760 - val_accuracy: 0.7390\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4808 - accuracy: 0.8449 - val_loss: 0.6700 - val_accuracy: 0.7380\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4759 - accuracy: 0.8453 - val_loss: 0.6709 - val_accuracy: 0.7370\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4725 - accuracy: 0.8495 - val_loss: 0.6693 - val_accuracy: 0.7390\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.4684 - accuracy: 0.8499 - val_loss: 0.6773 - val_accuracy: 0.7380\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.4651 - accuracy: 0.8492 - val_loss: 0.6720 - val_accuracy: 0.7370\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4608 - accuracy: 0.8520 - val_loss: 0.6665 - val_accuracy: 0.7350\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4573 - accuracy: 0.8533 - val_loss: 0.6722 - val_accuracy: 0.7420\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4537 - accuracy: 0.8553 - val_loss: 0.6742 - val_accuracy: 0.7400\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4500 - accuracy: 0.8567 - val_loss: 0.6658 - val_accuracy: 0.7390\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4464 - accuracy: 0.8568 - val_loss: 0.6716 - val_accuracy: 0.7350\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 1s 122us/step - loss: 0.4432 - accuracy: 0.8605 - val_loss: 0.6662 - val_accuracy: 0.7420\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.4393 - accuracy: 0.8616 - val_loss: 0.6664 - val_accuracy: 0.7420\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.4358 - accuracy: 0.8633 - val_loss: 0.6686 - val_accuracy: 0.7410\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.4321 - accuracy: 0.8653 - val_loss: 0.6711 - val_accuracy: 0.7390\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.4292 - accuracy: 0.8651 - val_loss: 0.6652 - val_accuracy: 0.7420\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.4255 - accuracy: 0.8653 - val_loss: 0.6668 - val_accuracy: 0.7400\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.4226 - accuracy: 0.8683 - val_loss: 0.6678 - val_accuracy: 0.7450\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4196 - accuracy: 0.8681 - val_loss: 0.6632 - val_accuracy: 0.7390\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4158 - accuracy: 0.8712 - val_loss: 0.6624 - val_accuracy: 0.7400\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4129 - accuracy: 0.8721 - val_loss: 0.6804 - val_accuracy: 0.7390\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4100 - accuracy: 0.8713 - val_loss: 0.6630 - val_accuracy: 0.7390\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.87 - 0s 32us/step - loss: 0.4064 - accuracy: 0.8740 - val_loss: 0.6670 - val_accuracy: 0.7370\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4034 - accuracy: 0.8732 - val_loss: 0.6701 - val_accuracy: 0.7430\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4004 - accuracy: 0.8769 - val_loss: 0.6637 - val_accuracy: 0.7400\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3969 - accuracy: 0.8767 - val_loss: 0.6625 - val_accuracy: 0.7410\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3940 - accuracy: 0.8771 - val_loss: 0.6679 - val_accuracy: 0.7370\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3909 - accuracy: 0.8791 - val_loss: 0.6628 - val_accuracy: 0.7420\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.3884 - accuracy: 0.8805 - val_loss: 0.6641 - val_accuracy: 0.7400\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.3853 - accuracy: 0.8808 - val_loss: 0.6647 - val_accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens, \n",
    "                          y_train_lb, \n",
    "                          epochs=150, \n",
    "                          callbacks=early_stopping, \n",
    "                          batch_size=256, \n",
    "                          validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 28us/step\n",
      "Training Loss: 0.412 \n",
      "Training Accuracy: 0.872\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 37us/step\n",
      "Test Loss: 0.618 \n",
      "Test Accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 2.6084 - accuracy: 0.1381 - val_loss: 2.5855 - val_accuracy: 0.1580\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.5859 - accuracy: 0.1687 - val_loss: 2.5716 - val_accuracy: 0.1850\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 2.5699 - accuracy: 0.1903 - val_loss: 2.5590 - val_accuracy: 0.2090\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.5548 - accuracy: 0.2129 - val_loss: 2.5449 - val_accuracy: 0.2190\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.5384 - accuracy: 0.2305 - val_loss: 2.5297 - val_accuracy: 0.2250\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.5212 - accuracy: 0.2395 - val_loss: 2.5136 - val_accuracy: 0.2410\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.5039 - accuracy: 0.2493 - val_loss: 2.4971 - val_accuracy: 0.2520\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 2.4858 - accuracy: 0.2597 - val_loss: 2.4798 - val_accuracy: 0.2640\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 2.4667 - accuracy: 0.2677 - val_loss: 2.4606 - val_accuracy: 0.2790\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.4458 - accuracy: 0.2835 - val_loss: 2.4388 - val_accuracy: 0.2990\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.4222 - accuracy: 0.3047 - val_loss: 2.4140 - val_accuracy: 0.3180\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.3946 - accuracy: 0.3221 - val_loss: 2.3846 - val_accuracy: 0.3420\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.3623 - accuracy: 0.3459 - val_loss: 2.3502 - val_accuracy: 0.3580\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.3256 - accuracy: 0.3711 - val_loss: 2.3145 - val_accuracy: 0.3750\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.2860 - accuracy: 0.3911 - val_loss: 2.2763 - val_accuracy: 0.3900\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.2442 - accuracy: 0.4107 - val_loss: 2.2351 - val_accuracy: 0.4050\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.2007 - accuracy: 0.4316 - val_loss: 2.1936 - val_accuracy: 0.4170\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.1563 - accuracy: 0.4477 - val_loss: 2.1517 - val_accuracy: 0.4410\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.1117 - accuracy: 0.4668 - val_loss: 2.1082 - val_accuracy: 0.4610\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.0677 - accuracy: 0.4831 - val_loss: 2.0659 - val_accuracy: 0.4780\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 2.0246 - accuracy: 0.4983 - val_loss: 2.0258 - val_accuracy: 0.4870\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.9821 - accuracy: 0.5105 - val_loss: 1.9828 - val_accuracy: 0.5180\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9406 - accuracy: 0.5339 - val_loss: 1.9463 - val_accuracy: 0.5150\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.9005 - accuracy: 0.5416 - val_loss: 1.9048 - val_accuracy: 0.5460\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8620 - accuracy: 0.5616 - val_loss: 1.8682 - val_accuracy: 0.5570\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8241 - accuracy: 0.5771 - val_loss: 1.8327 - val_accuracy: 0.5700\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.7880 - accuracy: 0.5911 - val_loss: 1.7993 - val_accuracy: 0.5740\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7532 - accuracy: 0.6107 - val_loss: 1.7651 - val_accuracy: 0.6030\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7200 - accuracy: 0.6257 - val_loss: 1.7354 - val_accuracy: 0.6050\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.6877 - accuracy: 0.6411 - val_loss: 1.7028 - val_accuracy: 0.6250\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.6569 - accuracy: 0.6551 - val_loss: 1.6733 - val_accuracy: 0.6290\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6276 - accuracy: 0.6676 - val_loss: 1.6459 - val_accuracy: 0.6430\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.5994 - accuracy: 0.6763 - val_loss: 1.6204 - val_accuracy: 0.6560\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5725 - accuracy: 0.6868 - val_loss: 1.5955 - val_accuracy: 0.6570\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5470 - accuracy: 0.6933 - val_loss: 1.5707 - val_accuracy: 0.6630\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5230 - accuracy: 0.7004 - val_loss: 1.5487 - val_accuracy: 0.6660\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.5002 - accuracy: 0.7056 - val_loss: 1.5292 - val_accuracy: 0.6750\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4787 - accuracy: 0.7128 - val_loss: 1.5092 - val_accuracy: 0.6770\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4579 - accuracy: 0.7171 - val_loss: 1.4921 - val_accuracy: 0.6840\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4384 - accuracy: 0.7216 - val_loss: 1.4765 - val_accuracy: 0.6790\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4205 - accuracy: 0.7240 - val_loss: 1.4571 - val_accuracy: 0.6930\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4029 - accuracy: 0.7291 - val_loss: 1.4408 - val_accuracy: 0.6860\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3866 - accuracy: 0.7312 - val_loss: 1.4282 - val_accuracy: 0.6950\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3708 - accuracy: 0.7347 - val_loss: 1.4153 - val_accuracy: 0.6900\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3560 - accuracy: 0.7388 - val_loss: 1.4016 - val_accuracy: 0.7030\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3418 - accuracy: 0.7428 - val_loss: 1.3869 - val_accuracy: 0.7060\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3282 - accuracy: 0.7469 - val_loss: 1.3794 - val_accuracy: 0.6990\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3155 - accuracy: 0.7488 - val_loss: 1.3685 - val_accuracy: 0.7110\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3030 - accuracy: 0.7525 - val_loss: 1.3561 - val_accuracy: 0.7090\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2913 - accuracy: 0.7561 - val_loss: 1.3474 - val_accuracy: 0.7120\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2795 - accuracy: 0.7604 - val_loss: 1.3407 - val_accuracy: 0.7070\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.2688 - accuracy: 0.7639 - val_loss: 1.3280 - val_accuracy: 0.7190\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2581 - accuracy: 0.7665 - val_loss: 1.3238 - val_accuracy: 0.7160\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2480 - accuracy: 0.7691 - val_loss: 1.3149 - val_accuracy: 0.7210\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2385 - accuracy: 0.7723 - val_loss: 1.3082 - val_accuracy: 0.7220\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2292 - accuracy: 0.7769 - val_loss: 1.2980 - val_accuracy: 0.7170\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2198 - accuracy: 0.7784 - val_loss: 1.2920 - val_accuracy: 0.7190\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.2109 - accuracy: 0.7792 - val_loss: 1.2843 - val_accuracy: 0.7180\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2022 - accuracy: 0.7827 - val_loss: 1.2811 - val_accuracy: 0.7200\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1940 - accuracy: 0.7829 - val_loss: 1.2735 - val_accuracy: 0.7200\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1854 - accuracy: 0.7852 - val_loss: 1.2712 - val_accuracy: 0.7260\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1774 - accuracy: 0.7851 - val_loss: 1.2617 - val_accuracy: 0.7200\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1698 - accuracy: 0.7859 - val_loss: 1.2606 - val_accuracy: 0.7200\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1627 - accuracy: 0.7893 - val_loss: 1.2524 - val_accuracy: 0.7210\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1553 - accuracy: 0.7921 - val_loss: 1.2443 - val_accuracy: 0.7270\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1475 - accuracy: 0.7916 - val_loss: 1.2425 - val_accuracy: 0.7260\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1405 - accuracy: 0.7951 - val_loss: 1.2364 - val_accuracy: 0.7290\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1333 - accuracy: 0.7973 - val_loss: 1.2294 - val_accuracy: 0.7310\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1267 - accuracy: 0.8016 - val_loss: 1.2293 - val_accuracy: 0.7220\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1199 - accuracy: 0.7993 - val_loss: 1.2272 - val_accuracy: 0.7280\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1137 - accuracy: 0.8045 - val_loss: 1.2179 - val_accuracy: 0.7280\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1070 - accuracy: 0.8035 - val_loss: 1.2133 - val_accuracy: 0.7340\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.1010 - accuracy: 0.8063 - val_loss: 1.2089 - val_accuracy: 0.7320\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0949 - accuracy: 0.8076 - val_loss: 1.2077 - val_accuracy: 0.7350\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0885 - accuracy: 0.8085 - val_loss: 1.2007 - val_accuracy: 0.7340\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0827 - accuracy: 0.8108 - val_loss: 1.1974 - val_accuracy: 0.7330\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0767 - accuracy: 0.8131 - val_loss: 1.1939 - val_accuracy: 0.7330\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0706 - accuracy: 0.8165 - val_loss: 1.1899 - val_accuracy: 0.7370\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0646 - accuracy: 0.8168 - val_loss: 1.1937 - val_accuracy: 0.7330\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0596 - accuracy: 0.8189 - val_loss: 1.1860 - val_accuracy: 0.7330\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0536 - accuracy: 0.8207 - val_loss: 1.1801 - val_accuracy: 0.7360\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0482 - accuracy: 0.8220 - val_loss: 1.1753 - val_accuracy: 0.7350\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0427 - accuracy: 0.8207 - val_loss: 1.1725 - val_accuracy: 0.7400\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0379 - accuracy: 0.8232 - val_loss: 1.1703 - val_accuracy: 0.7340\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0322 - accuracy: 0.8251 - val_loss: 1.1657 - val_accuracy: 0.7410\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0270 - accuracy: 0.8265 - val_loss: 1.1625 - val_accuracy: 0.7420\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0219 - accuracy: 0.8267 - val_loss: 1.1612 - val_accuracy: 0.7360\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0169 - accuracy: 0.8281 - val_loss: 1.1571 - val_accuracy: 0.7430\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0117 - accuracy: 0.8293 - val_loss: 1.1542 - val_accuracy: 0.7400\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0068 - accuracy: 0.8315 - val_loss: 1.1585 - val_accuracy: 0.7370\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0019 - accuracy: 0.8327 - val_loss: 1.1498 - val_accuracy: 0.7410\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9972 - accuracy: 0.8341 - val_loss: 1.1488 - val_accuracy: 0.7380\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9924 - accuracy: 0.8339 - val_loss: 1.1439 - val_accuracy: 0.7490\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9876 - accuracy: 0.8383 - val_loss: 1.1402 - val_accuracy: 0.7450\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9828 - accuracy: 0.8395 - val_loss: 1.1434 - val_accuracy: 0.7450\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9784 - accuracy: 0.8403 - val_loss: 1.1431 - val_accuracy: 0.7370\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9735 - accuracy: 0.8411 - val_loss: 1.1353 - val_accuracy: 0.7500\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9692 - accuracy: 0.8407 - val_loss: 1.1324 - val_accuracy: 0.7430\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9647 - accuracy: 0.8417 - val_loss: 1.1305 - val_accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9602 - accuracy: 0.8448 - val_loss: 1.1311 - val_accuracy: 0.7380\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9560 - accuracy: 0.8435 - val_loss: 1.1306 - val_accuracy: 0.7490\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9515 - accuracy: 0.8455 - val_loss: 1.1230 - val_accuracy: 0.7500\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9466 - accuracy: 0.8461 - val_loss: 1.1194 - val_accuracy: 0.7550\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9427 - accuracy: 0.8499 - val_loss: 1.1186 - val_accuracy: 0.7510\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9385 - accuracy: 0.8483 - val_loss: 1.1138 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9343 - accuracy: 0.8493 - val_loss: 1.1122 - val_accuracy: 0.7510\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9302 - accuracy: 0.8527 - val_loss: 1.1101 - val_accuracy: 0.7490\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9255 - accuracy: 0.8552 - val_loss: 1.1088 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9218 - accuracy: 0.8557 - val_loss: 1.1088 - val_accuracy: 0.7520\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9178 - accuracy: 0.8579 - val_loss: 1.1077 - val_accuracy: 0.7520\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9137 - accuracy: 0.8580 - val_loss: 1.1031 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9095 - accuracy: 0.8599 - val_loss: 1.1002 - val_accuracy: 0.7520\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9059 - accuracy: 0.8603 - val_loss: 1.0983 - val_accuracy: 0.7510\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9023 - accuracy: 0.8609 - val_loss: 1.0962 - val_accuracy: 0.7490\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8980 - accuracy: 0.8617 - val_loss: 1.0981 - val_accuracy: 0.7500\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.8943 - accuracy: 0.8620 - val_loss: 1.0948 - val_accuracy: 0.7540\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8902 - accuracy: 0.8628 - val_loss: 1.0919 - val_accuracy: 0.7460\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8868 - accuracy: 0.8644 - val_loss: 1.0913 - val_accuracy: 0.7470\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8830 - accuracy: 0.8655 - val_loss: 1.0873 - val_accuracy: 0.7460\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8790 - accuracy: 0.8669 - val_loss: 1.0868 - val_accuracy: 0.7470\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.8753 - accuracy: 0.8685 - val_loss: 1.0815 - val_accuracy: 0.7540\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8716 - accuracy: 0.8695 - val_loss: 1.0807 - val_accuracy: 0.7510\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8683 - accuracy: 0.8708 - val_loss: 1.0837 - val_accuracy: 0.7460\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8646 - accuracy: 0.8697 - val_loss: 1.0769 - val_accuracy: 0.7490\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8612 - accuracy: 0.8713 - val_loss: 1.0766 - val_accuracy: 0.7470\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.8576 - accuracy: 0.8715 - val_loss: 1.0774 - val_accuracy: 0.7470\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8539 - accuracy: 0.8731 - val_loss: 1.0719 - val_accuracy: 0.7500\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8505 - accuracy: 0.8751 - val_loss: 1.0746 - val_accuracy: 0.7460\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8471 - accuracy: 0.8755 - val_loss: 1.0708 - val_accuracy: 0.7470\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8438 - accuracy: 0.8749 - val_loss: 1.0689 - val_accuracy: 0.7470\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8401 - accuracy: 0.8767 - val_loss: 1.0687 - val_accuracy: 0.7460\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8370 - accuracy: 0.8779 - val_loss: 1.0683 - val_accuracy: 0.7440\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8336 - accuracy: 0.8783 - val_loss: 1.0642 - val_accuracy: 0.7490\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8304 - accuracy: 0.8779 - val_loss: 1.0624 - val_accuracy: 0.7510\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8271 - accuracy: 0.8791 - val_loss: 1.0661 - val_accuracy: 0.7430\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8236 - accuracy: 0.8811 - val_loss: 1.0625 - val_accuracy: 0.7500\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8208 - accuracy: 0.8812 - val_loss: 1.0584 - val_accuracy: 0.7470\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8171 - accuracy: 0.8816 - val_loss: 1.0617 - val_accuracy: 0.7460\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8144 - accuracy: 0.8851 - val_loss: 1.0584 - val_accuracy: 0.7450\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8107 - accuracy: 0.8835 - val_loss: 1.0554 - val_accuracy: 0.7470\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8078 - accuracy: 0.8855 - val_loss: 1.0581 - val_accuracy: 0.7440\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8050 - accuracy: 0.8855 - val_loss: 1.0626 - val_accuracy: 0.7450\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8019 - accuracy: 0.8859 - val_loss: 1.0540 - val_accuracy: 0.7470\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7987 - accuracy: 0.8876 - val_loss: 1.0508 - val_accuracy: 0.7430\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7956 - accuracy: 0.8900 - val_loss: 1.0524 - val_accuracy: 0.7450\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7929 - accuracy: 0.8891 - val_loss: 1.0493 - val_accuracy: 0.7440\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7897 - accuracy: 0.8892 - val_loss: 1.0517 - val_accuracy: 0.7430\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7868 - accuracy: 0.8913 - val_loss: 1.0509 - val_accuracy: 0.7490\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7840 - accuracy: 0.8921 - val_loss: 1.0471 - val_accuracy: 0.7500\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.7811 - accuracy: 0.8940 - val_loss: 1.0420 - val_accuracy: 0.7510\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['accuracy'] \n",
    "L2_val_acc_values = L2_model_dict['val_accuracy']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['accuracy'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 15.9977 - accuracy: 0.1651 - val_loss: 15.5843 - val_accuracy: 0.1690\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 15.2317 - accuracy: 0.1876 - val_loss: 14.8337 - val_accuracy: 0.1810\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 14.4907 - accuracy: 0.2140 - val_loss: 14.1052 - val_accuracy: 0.2050\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 13.7704 - accuracy: 0.2396 - val_loss: 13.3964 - val_accuracy: 0.2460\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 13.0684 - accuracy: 0.2703 - val_loss: 12.7066 - val_accuracy: 0.2920\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 12.3856 - accuracy: 0.3077 - val_loss: 12.0365 - val_accuracy: 0.3190\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 11.7227 - accuracy: 0.3384 - val_loss: 11.3860 - val_accuracy: 0.3300\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 11.0796 - accuracy: 0.3684 - val_loss: 10.7558 - val_accuracy: 0.3540\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 10.4569 - accuracy: 0.3984 - val_loss: 10.1455 - val_accuracy: 0.3730\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 9.8540 - accuracy: 0.4268 - val_loss: 9.5548 - val_accuracy: 0.4190\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 9.2708 - accuracy: 0.4608 - val_loss: 8.9843 - val_accuracy: 0.4540\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 8.7086 - accuracy: 0.4911 - val_loss: 8.4334 - val_accuracy: 0.4760\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 8.1686 - accuracy: 0.5187 - val_loss: 7.9057 - val_accuracy: 0.5130\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 7.6525 - accuracy: 0.5560 - val_loss: 7.4034 - val_accuracy: 0.5480\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 7.1592 - accuracy: 0.5765 - val_loss: 6.9243 - val_accuracy: 0.5560\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.6897 - accuracy: 0.5888 - val_loss: 6.4692 - val_accuracy: 0.5850\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 6.2455 - accuracy: 0.6089 - val_loss: 6.0373 - val_accuracy: 0.5940\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 5.8253 - accuracy: 0.6185 - val_loss: 5.6319 - val_accuracy: 0.5910\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 5.4297 - accuracy: 0.6264 - val_loss: 5.2501 - val_accuracy: 0.6110\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 5.0584 - accuracy: 0.6320 - val_loss: 4.8930 - val_accuracy: 0.6240\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.7104 - accuracy: 0.6448 - val_loss: 4.5564 - val_accuracy: 0.6220\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.3855 - accuracy: 0.6488 - val_loss: 4.2438 - val_accuracy: 0.6500\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 4.0830 - accuracy: 0.6601 - val_loss: 3.9550 - val_accuracy: 0.6470\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 3.8037 - accuracy: 0.6643 - val_loss: 3.6868 - val_accuracy: 0.6580\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 3.5470 - accuracy: 0.6679 - val_loss: 3.4419 - val_accuracy: 0.6560\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 3.3121 - accuracy: 0.6703 - val_loss: 3.2180 - val_accuracy: 0.6630\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 3.0988 - accuracy: 0.6755 - val_loss: 3.0163 - val_accuracy: 0.6640\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.9068 - accuracy: 0.6796 - val_loss: 2.8332 - val_accuracy: 0.6620\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.7363 - accuracy: 0.6796 - val_loss: 2.6740 - val_accuracy: 0.6680\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.5860 - accuracy: 0.6832 - val_loss: 2.5321 - val_accuracy: 0.6640\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.4560 - accuracy: 0.6836 - val_loss: 2.4117 - val_accuracy: 0.6710\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.3447 - accuracy: 0.6821 - val_loss: 2.3103 - val_accuracy: 0.6740\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.2525 - accuracy: 0.6841 - val_loss: 2.2262 - val_accuracy: 0.6780\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.1788 - accuracy: 0.6856 - val_loss: 2.1600 - val_accuracy: 0.6730\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.1216 - accuracy: 0.6859 - val_loss: 2.1094 - val_accuracy: 0.6750\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.0779 - accuracy: 0.6877 - val_loss: 2.0747 - val_accuracy: 0.6750\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.0457 - accuracy: 0.6880 - val_loss: 2.0503 - val_accuracy: 0.6750\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.0198 - accuracy: 0.6869 - val_loss: 2.0241 - val_accuracy: 0.6740\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9973 - accuracy: 0.6875 - val_loss: 1.9984 - val_accuracy: 0.6800\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9773 - accuracy: 0.6897 - val_loss: 1.9815 - val_accuracy: 0.6780\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9593 - accuracy: 0.6885 - val_loss: 1.9650 - val_accuracy: 0.6690\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.9418 - accuracy: 0.6896 - val_loss: 1.9457 - val_accuracy: 0.6790\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.9256 - accuracy: 0.6897 - val_loss: 1.9282 - val_accuracy: 0.6770\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9098 - accuracy: 0.6915 - val_loss: 1.9159 - val_accuracy: 0.6740\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.8955 - accuracy: 0.6901 - val_loss: 1.8999 - val_accuracy: 0.6770\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.8810 - accuracy: 0.6931 - val_loss: 1.8888 - val_accuracy: 0.6780\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8676 - accuracy: 0.6909 - val_loss: 1.8718 - val_accuracy: 0.6800\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8546 - accuracy: 0.6929 - val_loss: 1.8619 - val_accuracy: 0.6830\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.8416 - accuracy: 0.6927 - val_loss: 1.8498 - val_accuracy: 0.6770\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.8292 - accuracy: 0.6936 - val_loss: 1.8351 - val_accuracy: 0.6800\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.8174 - accuracy: 0.6953 - val_loss: 1.8238 - val_accuracy: 0.6790\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.8055 - accuracy: 0.6951 - val_loss: 1.8160 - val_accuracy: 0.6810\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.7947 - accuracy: 0.6968 - val_loss: 1.8065 - val_accuracy: 0.6790\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.7837 - accuracy: 0.6969 - val_loss: 1.7894 - val_accuracy: 0.6840\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.7726 - accuracy: 0.6984 - val_loss: 1.7789 - val_accuracy: 0.6840\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.7621 - accuracy: 0.6984 - val_loss: 1.7695 - val_accuracy: 0.6830\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.7522 - accuracy: 0.7004 - val_loss: 1.7631 - val_accuracy: 0.6790\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.7422 - accuracy: 0.7003 - val_loss: 1.7531 - val_accuracy: 0.6840\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.7322 - accuracy: 0.7019 - val_loss: 1.7403 - val_accuracy: 0.6880\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.7226 - accuracy: 0.7021 - val_loss: 1.7296 - val_accuracy: 0.6840\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.7131 - accuracy: 0.7033 - val_loss: 1.7218 - val_accuracy: 0.6840\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.7037 - accuracy: 0.7048 - val_loss: 1.7139 - val_accuracy: 0.6870\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.6943 - accuracy: 0.7048 - val_loss: 1.7047 - val_accuracy: 0.6890\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6852 - accuracy: 0.7061 - val_loss: 1.6945 - val_accuracy: 0.6870\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.6759 - accuracy: 0.7067 - val_loss: 1.6848 - val_accuracy: 0.6850\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.6679 - accuracy: 0.7063 - val_loss: 1.6762 - val_accuracy: 0.6850\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.6589 - accuracy: 0.7052 - val_loss: 1.6701 - val_accuracy: 0.6850\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.6506 - accuracy: 0.7061 - val_loss: 1.6611 - val_accuracy: 0.6870\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6425 - accuracy: 0.7065 - val_loss: 1.6552 - val_accuracy: 0.6870\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.6346 - accuracy: 0.7065 - val_loss: 1.6453 - val_accuracy: 0.6860\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.6261 - accuracy: 0.7055 - val_loss: 1.6389 - val_accuracy: 0.6880\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.6180 - accuracy: 0.7069 - val_loss: 1.6291 - val_accuracy: 0.6860\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.6100 - accuracy: 0.7088 - val_loss: 1.6244 - val_accuracy: 0.6870\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6028 - accuracy: 0.7067 - val_loss: 1.6203 - val_accuracy: 0.6870\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.5948 - accuracy: 0.7093 - val_loss: 1.6072 - val_accuracy: 0.6890\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.5867 - accuracy: 0.7083 - val_loss: 1.5977 - val_accuracy: 0.6850\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.5794 - accuracy: 0.7083 - val_loss: 1.5932 - val_accuracy: 0.6910\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5726 - accuracy: 0.7100 - val_loss: 1.5858 - val_accuracy: 0.6870\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.5656 - accuracy: 0.7088 - val_loss: 1.5782 - val_accuracy: 0.6860\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.5576 - accuracy: 0.7103 - val_loss: 1.5715 - val_accuracy: 0.6870\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5510 - accuracy: 0.7104 - val_loss: 1.5660 - val_accuracy: 0.6930\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.5434 - accuracy: 0.7123 - val_loss: 1.5543 - val_accuracy: 0.6870\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.5369 - accuracy: 0.7097 - val_loss: 1.5504 - val_accuracy: 0.6870\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5295 - accuracy: 0.7123 - val_loss: 1.5444 - val_accuracy: 0.6890\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5225 - accuracy: 0.7120 - val_loss: 1.5358 - val_accuracy: 0.6880\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.5162 - accuracy: 0.7115 - val_loss: 1.5334 - val_accuracy: 0.6880\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5095 - accuracy: 0.7111 - val_loss: 1.5250 - val_accuracy: 0.6860\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.5030 - accuracy: 0.7120 - val_loss: 1.5186 - val_accuracy: 0.6900\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4969 - accuracy: 0.7137 - val_loss: 1.5104 - val_accuracy: 0.6880\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4899 - accuracy: 0.7128 - val_loss: 1.5101 - val_accuracy: 0.6960\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4842 - accuracy: 0.7133 - val_loss: 1.4993 - val_accuracy: 0.6920\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4774 - accuracy: 0.7137 - val_loss: 1.4953 - val_accuracy: 0.6920\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4715 - accuracy: 0.7135 - val_loss: 1.4903 - val_accuracy: 0.6890\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4653 - accuracy: 0.7141 - val_loss: 1.4829 - val_accuracy: 0.6890\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4595 - accuracy: 0.7145 - val_loss: 1.4766 - val_accuracy: 0.6940\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4534 - accuracy: 0.7149 - val_loss: 1.4709 - val_accuracy: 0.6910\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4477 - accuracy: 0.7137 - val_loss: 1.4640 - val_accuracy: 0.6880\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4419 - accuracy: 0.7152 - val_loss: 1.4615 - val_accuracy: 0.6930\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4361 - accuracy: 0.7176 - val_loss: 1.4557 - val_accuracy: 0.6890\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4303 - accuracy: 0.7157 - val_loss: 1.4477 - val_accuracy: 0.6920\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4242 - accuracy: 0.7173 - val_loss: 1.4457 - val_accuracy: 0.6920\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4192 - accuracy: 0.7148 - val_loss: 1.4410 - val_accuracy: 0.6960\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.4135 - accuracy: 0.7169 - val_loss: 1.4366 - val_accuracy: 0.6940\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4084 - accuracy: 0.7156 - val_loss: 1.4303 - val_accuracy: 0.6950\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4028 - accuracy: 0.7176 - val_loss: 1.4232 - val_accuracy: 0.6920\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3972 - accuracy: 0.7177 - val_loss: 1.4232 - val_accuracy: 0.6930\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3931 - accuracy: 0.7191 - val_loss: 1.4130 - val_accuracy: 0.6950\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.3871 - accuracy: 0.7191 - val_loss: 1.4090 - val_accuracy: 0.6930\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3822 - accuracy: 0.7191 - val_loss: 1.4024 - val_accuracy: 0.6940\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3766 - accuracy: 0.7185 - val_loss: 1.3984 - val_accuracy: 0.6930\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3721 - accuracy: 0.7183 - val_loss: 1.3950 - val_accuracy: 0.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3666 - accuracy: 0.7195 - val_loss: 1.3900 - val_accuracy: 0.6930\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3618 - accuracy: 0.7196 - val_loss: 1.3826 - val_accuracy: 0.6970\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3571 - accuracy: 0.7211 - val_loss: 1.3798 - val_accuracy: 0.6970\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3525 - accuracy: 0.7211 - val_loss: 1.3734 - val_accuracy: 0.6940\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3476 - accuracy: 0.7221 - val_loss: 1.3737 - val_accuracy: 0.6950\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3427 - accuracy: 0.7211 - val_loss: 1.3667 - val_accuracy: 0.6950\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.3379 - accuracy: 0.7204 - val_loss: 1.3617 - val_accuracy: 0.6960\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3336 - accuracy: 0.7207 - val_loss: 1.3560 - val_accuracy: 0.7010\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3286 - accuracy: 0.7224 - val_loss: 1.3504 - val_accuracy: 0.6970\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3241 - accuracy: 0.7247 - val_loss: 1.3473 - val_accuracy: 0.6930\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.3194 - accuracy: 0.7219 - val_loss: 1.3524 - val_accuracy: 0.6980\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3155 - accuracy: 0.7239 - val_loss: 1.3485 - val_accuracy: 0.6940\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.3110 - accuracy: 0.7231 - val_loss: 1.3333 - val_accuracy: 0.6970\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3062 - accuracy: 0.7247 - val_loss: 1.3325 - val_accuracy: 0.6960\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3021 - accuracy: 0.7247 - val_loss: 1.3250 - val_accuracy: 0.6980\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2972 - accuracy: 0.7249 - val_loss: 1.3291 - val_accuracy: 0.6930\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2934 - accuracy: 0.7265 - val_loss: 1.3190 - val_accuracy: 0.6980\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2892 - accuracy: 0.7235 - val_loss: 1.3170 - val_accuracy: 0.7010\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2850 - accuracy: 0.7264 - val_loss: 1.3092 - val_accuracy: 0.6970\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.2805 - accuracy: 0.7279 - val_loss: 1.3077 - val_accuracy: 0.6930\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2769 - accuracy: 0.7261 - val_loss: 1.3055 - val_accuracy: 0.6970\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.2726 - accuracy: 0.7277 - val_loss: 1.2974 - val_accuracy: 0.6980\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2679 - accuracy: 0.7269 - val_loss: 1.2931 - val_accuracy: 0.7030\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2643 - accuracy: 0.7279 - val_loss: 1.2926 - val_accuracy: 0.6980\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2600 - accuracy: 0.7271 - val_loss: 1.2893 - val_accuracy: 0.7000\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2568 - accuracy: 0.7284 - val_loss: 1.2834 - val_accuracy: 0.7040\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2524 - accuracy: 0.7279 - val_loss: 1.2800 - val_accuracy: 0.7030\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2484 - accuracy: 0.7283 - val_loss: 1.2750 - val_accuracy: 0.7010\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.2449 - accuracy: 0.7291 - val_loss: 1.2724 - val_accuracy: 0.6930\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2407 - accuracy: 0.7303 - val_loss: 1.2709 - val_accuracy: 0.6940\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.2372 - accuracy: 0.7272 - val_loss: 1.2641 - val_accuracy: 0.7020\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.2333 - accuracy: 0.7289 - val_loss: 1.2652 - val_accuracy: 0.7050\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2297 - accuracy: 0.7297 - val_loss: 1.2671 - val_accuracy: 0.7010\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2269 - accuracy: 0.7301 - val_loss: 1.2542 - val_accuracy: 0.7010\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2229 - accuracy: 0.7320 - val_loss: 1.2524 - val_accuracy: 0.7020\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2189 - accuracy: 0.7300 - val_loss: 1.2467 - val_accuracy: 0.7020\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2155 - accuracy: 0.7323 - val_loss: 1.2416 - val_accuracy: 0.7080\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2118 - accuracy: 0.7311 - val_loss: 1.2407 - val_accuracy: 0.7040\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2093 - accuracy: 0.7312 - val_loss: 1.2370 - val_accuracy: 0.7040\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 1.9915 - accuracy: 0.1367 - val_loss: 1.9395 - val_accuracy: 0.1600\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.9583 - accuracy: 0.1529 - val_loss: 1.9303 - val_accuracy: 0.1650\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9499 - accuracy: 0.1561 - val_loss: 1.9240 - val_accuracy: 0.1820\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9377 - accuracy: 0.1765 - val_loss: 1.9180 - val_accuracy: 0.1990\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.9304 - accuracy: 0.1751 - val_loss: 1.9119 - val_accuracy: 0.2080\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.9246 - accuracy: 0.1827 - val_loss: 1.9061 - val_accuracy: 0.2120\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.9189 - accuracy: 0.1932 - val_loss: 1.9001 - val_accuracy: 0.2180\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.9079 - accuracy: 0.2003 - val_loss: 1.8930 - val_accuracy: 0.2220\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.9002 - accuracy: 0.2185 - val_loss: 1.8846 - val_accuracy: 0.2200\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.8982 - accuracy: 0.2175 - val_loss: 1.8766 - val_accuracy: 0.2290\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.8852 - accuracy: 0.2200 - val_loss: 1.8665 - val_accuracy: 0.2340\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.8781 - accuracy: 0.2363 - val_loss: 1.8557 - val_accuracy: 0.2420\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.8682 - accuracy: 0.2405 - val_loss: 1.8434 - val_accuracy: 0.2530\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.8660 - accuracy: 0.2375 - val_loss: 1.8292 - val_accuracy: 0.2610\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.8507 - accuracy: 0.2440 - val_loss: 1.8130 - val_accuracy: 0.2740\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 1.8402 - accuracy: 0.2544 - val_loss: 1.7978 - val_accuracy: 0.2850\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 1.8268 - accuracy: 0.2617 - val_loss: 1.7806 - val_accuracy: 0.3050\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.8135 - accuracy: 0.2784 - val_loss: 1.7625 - val_accuracy: 0.3270\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.7981 - accuracy: 0.2912 - val_loss: 1.7406 - val_accuracy: 0.3430\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 1.7770 - accuracy: 0.3019 - val_loss: 1.7175 - val_accuracy: 0.3500\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.7638 - accuracy: 0.3037 - val_loss: 1.6952 - val_accuracy: 0.3680\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 1.7532 - accuracy: 0.3148 - val_loss: 1.6731 - val_accuracy: 0.3960\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.7383 - accuracy: 0.3245 - val_loss: 1.6461 - val_accuracy: 0.4180\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.7152 - accuracy: 0.3309 - val_loss: 1.6208 - val_accuracy: 0.4410\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.6944 - accuracy: 0.3480 - val_loss: 1.5935 - val_accuracy: 0.4550\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.6786 - accuracy: 0.3464 - val_loss: 1.5684 - val_accuracy: 0.4820\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.6618 - accuracy: 0.3549 - val_loss: 1.5437 - val_accuracy: 0.4950\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.6396 - accuracy: 0.3748 - val_loss: 1.5159 - val_accuracy: 0.5100\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.6215 - accuracy: 0.3711 - val_loss: 1.4895 - val_accuracy: 0.5260\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.6105 - accuracy: 0.3803 - val_loss: 1.4662 - val_accuracy: 0.5370\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 1.5877 - accuracy: 0.3956 - val_loss: 1.4374 - val_accuracy: 0.5560\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 1.5631 - accuracy: 0.4044 - val_loss: 1.4106 - val_accuracy: 0.5650\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.5473 - accuracy: 0.4089 - val_loss: 1.3856 - val_accuracy: 0.5850\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.5204 - accuracy: 0.4180 - val_loss: 1.3625 - val_accuracy: 0.5850\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 1.5100 - accuracy: 0.4299 - val_loss: 1.3370 - val_accuracy: 0.6060\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.5028 - accuracy: 0.4333 - val_loss: 1.3165 - val_accuracy: 0.6130\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.4792 - accuracy: 0.4400 - val_loss: 1.2941 - val_accuracy: 0.6210\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.4489 - accuracy: 0.4560 - val_loss: 1.2687 - val_accuracy: 0.6370\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.4484 - accuracy: 0.4584 - val_loss: 1.2496 - val_accuracy: 0.6410\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 1.4183 - accuracy: 0.4633 - val_loss: 1.2257 - val_accuracy: 0.6520\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.4200 - accuracy: 0.4625 - val_loss: 1.2068 - val_accuracy: 0.6570\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.4076 - accuracy: 0.4701 - val_loss: 1.1913 - val_accuracy: 0.6600\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.3854 - accuracy: 0.4771 - val_loss: 1.1722 - val_accuracy: 0.6690\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.3769 - accuracy: 0.4841 - val_loss: 1.1577 - val_accuracy: 0.6640\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.3605 - accuracy: 0.4967 - val_loss: 1.1391 - val_accuracy: 0.6680\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.3430 - accuracy: 0.5003 - val_loss: 1.1219 - val_accuracy: 0.6750\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.3322 - accuracy: 0.4967 - val_loss: 1.1067 - val_accuracy: 0.6780\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.3193 - accuracy: 0.5151 - val_loss: 1.0918 - val_accuracy: 0.6820\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.3015 - accuracy: 0.5215 - val_loss: 1.0754 - val_accuracy: 0.6850\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 1.2982 - accuracy: 0.5188 - val_loss: 1.0599 - val_accuracy: 0.6890\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 1.2896 - accuracy: 0.5243 - val_loss: 1.0450 - val_accuracy: 0.6970\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 1.2719 - accuracy: 0.5281 - val_loss: 1.0327 - val_accuracy: 0.6950\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.2622 - accuracy: 0.5363 - val_loss: 1.0201 - val_accuracy: 0.7000\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 1.2561 - accuracy: 0.5377 - val_loss: 1.0073 - val_accuracy: 0.6970\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.2385 - accuracy: 0.5411 - val_loss: 0.9937 - val_accuracy: 0.6990\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 1s 90us/step - loss: 1.2126 - accuracy: 0.5508 - val_loss: 0.9793 - val_accuracy: 0.7010\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.2035 - accuracy: 0.5539 - val_loss: 0.9666 - val_accuracy: 0.7070\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.2052 - accuracy: 0.5649 - val_loss: 0.9596 - val_accuracy: 0.7010\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.1951 - accuracy: 0.5579 - val_loss: 0.9487 - val_accuracy: 0.7070\n",
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.1891 - accuracy: 0.5632 - val_loss: 0.9411 - val_accuracy: 0.6980\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.1834 - accuracy: 0.5627 - val_loss: 0.9317 - val_accuracy: 0.7030\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.1741 - accuracy: 0.5763 - val_loss: 0.9244 - val_accuracy: 0.7060\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1648 - accuracy: 0.5756 - val_loss: 0.9159 - val_accuracy: 0.7010\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.1481 - accuracy: 0.5715 - val_loss: 0.9058 - val_accuracy: 0.7090\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1405 - accuracy: 0.5900 - val_loss: 0.8957 - val_accuracy: 0.7100\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.1453 - accuracy: 0.5809 - val_loss: 0.8926 - val_accuracy: 0.7050\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 1.1186 - accuracy: 0.5935 - val_loss: 0.8808 - val_accuracy: 0.7040\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.1220 - accuracy: 0.5891 - val_loss: 0.8754 - val_accuracy: 0.7070\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.1182 - accuracy: 0.5952 - val_loss: 0.8657 - val_accuracy: 0.7070\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 1.1088 - accuracy: 0.5895 - val_loss: 0.8626 - val_accuracy: 0.7070\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.1022 - accuracy: 0.5977 - val_loss: 0.8535 - val_accuracy: 0.7140\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 1.0868 - accuracy: 0.6112 - val_loss: 0.8452 - val_accuracy: 0.7110\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.0881 - accuracy: 0.6084 - val_loss: 0.8401 - val_accuracy: 0.7090\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.0838 - accuracy: 0.6027 - val_loss: 0.8337 - val_accuracy: 0.7140\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.0846 - accuracy: 0.6105 - val_loss: 0.8312 - val_accuracy: 0.7090\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 1.0729 - accuracy: 0.6088 - val_loss: 0.8260 - val_accuracy: 0.7100\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.0639 - accuracy: 0.6088 - val_loss: 0.8211 - val_accuracy: 0.7140\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.0665 - accuracy: 0.6051 - val_loss: 0.8164 - val_accuracy: 0.7140\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.0582 - accuracy: 0.6091 - val_loss: 0.8126 - val_accuracy: 0.7160\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.0362 - accuracy: 0.6288 - val_loss: 0.8044 - val_accuracy: 0.7130\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 1.0362 - accuracy: 0.6244 - val_loss: 0.7992 - val_accuracy: 0.7180\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.0405 - accuracy: 0.6184 - val_loss: 0.7944 - val_accuracy: 0.7190\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0377 - accuracy: 0.6235 - val_loss: 0.7897 - val_accuracy: 0.7190\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 1.0192 - accuracy: 0.6247 - val_loss: 0.7873 - val_accuracy: 0.7180\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 1.0355 - accuracy: 0.6241 - val_loss: 0.7837 - val_accuracy: 0.7160\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 1.0073 - accuracy: 0.6379 - val_loss: 0.7782 - val_accuracy: 0.7210\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 1.0140 - accuracy: 0.6284 - val_loss: 0.7744 - val_accuracy: 0.7230\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.0025 - accuracy: 0.6404 - val_loss: 0.7703 - val_accuracy: 0.7230\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.9999 - accuracy: 0.6368 - val_loss: 0.7654 - val_accuracy: 0.7200\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9934 - accuracy: 0.6379 - val_loss: 0.7632 - val_accuracy: 0.7200\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.9815 - accuracy: 0.6431 - val_loss: 0.7581 - val_accuracy: 0.7200\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.9855 - accuracy: 0.6349 - val_loss: 0.7555 - val_accuracy: 0.7200\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9848 - accuracy: 0.6476 - val_loss: 0.7523 - val_accuracy: 0.7210\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.9813 - accuracy: 0.6513 - val_loss: 0.7490 - val_accuracy: 0.7190\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9684 - accuracy: 0.6463 - val_loss: 0.7454 - val_accuracy: 0.7230\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9687 - accuracy: 0.6540 - val_loss: 0.7408 - val_accuracy: 0.7240\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9756 - accuracy: 0.6408 - val_loss: 0.7382 - val_accuracy: 0.7190\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9599 - accuracy: 0.6577 - val_loss: 0.7342 - val_accuracy: 0.7190\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.9550 - accuracy: 0.6524 - val_loss: 0.7332 - val_accuracy: 0.7190\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9629 - accuracy: 0.6531 - val_loss: 0.7311 - val_accuracy: 0.7210\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9657 - accuracy: 0.6455 - val_loss: 0.7313 - val_accuracy: 0.7200\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.9478 - accuracy: 0.6580 - val_loss: 0.7271 - val_accuracy: 0.7190\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 1s 98us/step - loss: 0.9536 - accuracy: 0.6524 - val_loss: 0.7256 - val_accuracy: 0.7190\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.9451 - accuracy: 0.6639 - val_loss: 0.7228 - val_accuracy: 0.7200\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.9374 - accuracy: 0.6675 - val_loss: 0.7194 - val_accuracy: 0.7220\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.9446 - accuracy: 0.6616 - val_loss: 0.7181 - val_accuracy: 0.7260\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.9359 - accuracy: 0.6535 - val_loss: 0.7145 - val_accuracy: 0.7270\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.9341 - accuracy: 0.6692 - val_loss: 0.7149 - val_accuracy: 0.7300\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.9293 - accuracy: 0.6699 - val_loss: 0.7085 - val_accuracy: 0.7320\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 67us/step - loss: 0.9358 - accuracy: 0.6633 - val_loss: 0.7092 - val_accuracy: 0.7320\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.9263 - accuracy: 0.6631 - val_loss: 0.7098 - val_accuracy: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.9196 - accuracy: 0.6663 - val_loss: 0.7034 - val_accuracy: 0.7320\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.9181 - accuracy: 0.6717 - val_loss: 0.7062 - val_accuracy: 0.7270\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 0.9027 - accuracy: 0.6709 - val_loss: 0.7023 - val_accuracy: 0.7330\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.9184 - accuracy: 0.6659 - val_loss: 0.7010 - val_accuracy: 0.7320\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8968 - accuracy: 0.6780 - val_loss: 0.6949 - val_accuracy: 0.7360\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.9016 - accuracy: 0.6773 - val_loss: 0.6931 - val_accuracy: 0.7360\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.9017 - accuracy: 0.6755 - val_loss: 0.6940 - val_accuracy: 0.7290\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.8747 - accuracy: 0.6811 - val_loss: 0.6879 - val_accuracy: 0.7330\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8968 - accuracy: 0.6748 - val_loss: 0.6882 - val_accuracy: 0.7350\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 63us/step - loss: 0.8887 - accuracy: 0.6784 - val_loss: 0.6862 - val_accuracy: 0.7310\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8854 - accuracy: 0.6804 - val_loss: 0.6839 - val_accuracy: 0.7400\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8893 - accuracy: 0.6749 - val_loss: 0.6837 - val_accuracy: 0.7400\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8830 - accuracy: 0.6751 - val_loss: 0.6812 - val_accuracy: 0.7390\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.8890 - accuracy: 0.6741 - val_loss: 0.6792 - val_accuracy: 0.7370\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8807 - accuracy: 0.6780 - val_loss: 0.6785 - val_accuracy: 0.7350\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8654 - accuracy: 0.6824 - val_loss: 0.6776 - val_accuracy: 0.7390\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8767 - accuracy: 0.6789 - val_loss: 0.6762 - val_accuracy: 0.7370\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8730 - accuracy: 0.6844 - val_loss: 0.6772 - val_accuracy: 0.7340\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8622 - accuracy: 0.6820 - val_loss: 0.6752 - val_accuracy: 0.7350\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8749 - accuracy: 0.6883 - val_loss: 0.6749 - val_accuracy: 0.7360\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8583 - accuracy: 0.6880 - val_loss: 0.6705 - val_accuracy: 0.7410\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.8711 - accuracy: 0.6823 - val_loss: 0.6729 - val_accuracy: 0.7370\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8605 - accuracy: 0.6881 - val_loss: 0.6703 - val_accuracy: 0.7400\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.8586 - accuracy: 0.6819 - val_loss: 0.6681 - val_accuracy: 0.7410\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.8473 - accuracy: 0.6895 - val_loss: 0.6660 - val_accuracy: 0.7360\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.8654 - accuracy: 0.6844 - val_loss: 0.6647 - val_accuracy: 0.7410\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.8477 - accuracy: 0.6936 - val_loss: 0.6655 - val_accuracy: 0.7410\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8400 - accuracy: 0.6989 - val_loss: 0.6632 - val_accuracy: 0.7390\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8340 - accuracy: 0.6935 - val_loss: 0.6618 - val_accuracy: 0.7440\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.8405 - accuracy: 0.6917 - val_loss: 0.6614 - val_accuracy: 0.7440\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.8282 - accuracy: 0.6953 - val_loss: 0.6565 - val_accuracy: 0.7400\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 0.8344 - accuracy: 0.7012 - val_loss: 0.6575 - val_accuracy: 0.7440\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.8269 - accuracy: 0.6917 - val_loss: 0.6554 - val_accuracy: 0.7410\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8307 - accuracy: 0.7032 - val_loss: 0.6555 - val_accuracy: 0.7440\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.8229 - accuracy: 0.6991 - val_loss: 0.6565 - val_accuracy: 0.7430\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.8246 - accuracy: 0.6996 - val_loss: 0.6540 - val_accuracy: 0.7390\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.8364 - accuracy: 0.6984 - val_loss: 0.6533 - val_accuracy: 0.7440\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8131 - accuracy: 0.7029 - val_loss: 0.6520 - val_accuracy: 0.7480\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 1s 69us/step - loss: 0.8188 - accuracy: 0.7040 - val_loss: 0.6538 - val_accuracy: 0.7470\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6301ba6f4c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_lb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8809 - accuracy: 0.2217 - val_loss: 1.8026 - val_accuracy: 0.2943\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6635 - accuracy: 0.3954 - val_loss: 1.5317 - val_accuracy: 0.4773\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3601 - accuracy: 0.5495 - val_loss: 1.2284 - val_accuracy: 0.6010\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.0865 - accuracy: 0.6578 - val_loss: 1.0015 - val_accuracy: 0.6765\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.9053 - accuracy: 0.7067 - val_loss: 0.8653 - val_accuracy: 0.7120\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.7975 - accuracy: 0.7274 - val_loss: 0.7848 - val_accuracy: 0.7258\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.7314 - accuracy: 0.7424 - val_loss: 0.7357 - val_accuracy: 0.7375\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6881 - accuracy: 0.7531 - val_loss: 0.7029 - val_accuracy: 0.7427\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.6569 - accuracy: 0.7618 - val_loss: 0.6778 - val_accuracy: 0.7525\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.6329 - accuracy: 0.7694 - val_loss: 0.6610 - val_accuracy: 0.7575\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.6137 - accuracy: 0.7765 - val_loss: 0.6466 - val_accuracy: 0.7620\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5976 - accuracy: 0.7814 - val_loss: 0.6334 - val_accuracy: 0.7613\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5839 - accuracy: 0.7858 - val_loss: 0.6258 - val_accuracy: 0.7710\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5717 - accuracy: 0.7908 - val_loss: 0.6167 - val_accuracy: 0.7697\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5605 - accuracy: 0.7951 - val_loss: 0.6082 - val_accuracy: 0.7750\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5507 - accuracy: 0.7996 - val_loss: 0.6030 - val_accuracy: 0.7815\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5416 - accuracy: 0.8031 - val_loss: 0.5944 - val_accuracy: 0.7793\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5333 - accuracy: 0.8067 - val_loss: 0.5898 - val_accuracy: 0.7878\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5256 - accuracy: 0.8099 - val_loss: 0.5832 - val_accuracy: 0.7870\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5182 - accuracy: 0.8123 - val_loss: 0.5829 - val_accuracy: 0.7835\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5114 - accuracy: 0.8148 - val_loss: 0.5802 - val_accuracy: 0.7837\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5052 - accuracy: 0.8179 - val_loss: 0.5719 - val_accuracy: 0.7840\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4991 - accuracy: 0.8204 - val_loss: 0.5695 - val_accuracy: 0.7900\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4934 - accuracy: 0.8225 - val_loss: 0.5648 - val_accuracy: 0.7920\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4884 - accuracy: 0.8242 - val_loss: 0.5676 - val_accuracy: 0.7990\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4833 - accuracy: 0.8263 - val_loss: 0.5626 - val_accuracy: 0.7912\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4784 - accuracy: 0.8281 - val_loss: 0.5593 - val_accuracy: 0.7960\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4739 - accuracy: 0.8305 - val_loss: 0.5585 - val_accuracy: 0.7980\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4695 - accuracy: 0.8311 - val_loss: 0.5520 - val_accuracy: 0.7985\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4653 - accuracy: 0.8339 - val_loss: 0.5513 - val_accuracy: 0.8012\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4613 - accuracy: 0.8352 - val_loss: 0.5482 - val_accuracy: 0.8040\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4574 - accuracy: 0.8367 - val_loss: 0.5545 - val_accuracy: 0.7995\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4539 - accuracy: 0.8382 - val_loss: 0.5521 - val_accuracy: 0.8010\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4504 - accuracy: 0.8388 - val_loss: 0.5446 - val_accuracy: 0.8055\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4468 - accuracy: 0.8416 - val_loss: 0.5446 - val_accuracy: 0.8012\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4439 - accuracy: 0.8416 - val_loss: 0.5435 - val_accuracy: 0.8050\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4405 - accuracy: 0.8437 - val_loss: 0.5408 - val_accuracy: 0.8050\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4377 - accuracy: 0.8448 - val_loss: 0.5428 - val_accuracy: 0.8035\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4347 - accuracy: 0.8458 - val_loss: 0.5400 - val_accuracy: 0.8050\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4318 - accuracy: 0.8473 - val_loss: 0.5418 - val_accuracy: 0.8040\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4290 - accuracy: 0.8492 - val_loss: 0.5389 - val_accuracy: 0.8062\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4262 - accuracy: 0.8495 - val_loss: 0.5410 - val_accuracy: 0.8058\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4239 - accuracy: 0.8501 - val_loss: 0.5394 - val_accuracy: 0.8062\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4212 - accuracy: 0.8515 - val_loss: 0.5388 - val_accuracy: 0.8120\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4189 - accuracy: 0.8518 - val_loss: 0.5374 - val_accuracy: 0.8092\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4165 - accuracy: 0.8529 - val_loss: 0.5363 - val_accuracy: 0.8075\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4143 - accuracy: 0.8540 - val_loss: 0.5355 - val_accuracy: 0.8095\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4121 - accuracy: 0.8551 - val_loss: 0.5377 - val_accuracy: 0.8125\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4098 - accuracy: 0.8563 - val_loss: 0.5357 - val_accuracy: 0.8127\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4077 - accuracy: 0.8564 - val_loss: 0.5366 - val_accuracy: 0.8090\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4059 - accuracy: 0.8578 - val_loss: 0.5355 - val_accuracy: 0.8133\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4037 - accuracy: 0.8580 - val_loss: 0.5353 - val_accuracy: 0.8133\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4018 - accuracy: 0.8590 - val_loss: 0.5376 - val_accuracy: 0.8090\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3995 - accuracy: 0.8599 - val_loss: 0.5380 - val_accuracy: 0.8142\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3977 - accuracy: 0.8602 - val_loss: 0.5347 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3959 - accuracy: 0.8607 - val_loss: 0.5372 - val_accuracy: 0.8108\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3941 - accuracy: 0.8616 - val_loss: 0.5345 - val_accuracy: 0.8125\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3926 - accuracy: 0.8626 - val_loss: 0.5427 - val_accuracy: 0.8090\n",
      "Epoch 59/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3906 - accuracy: 0.8630 - val_loss: 0.5344 - val_accuracy: 0.8142\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3888 - accuracy: 0.8641 - val_loss: 0.5389 - val_accuracy: 0.8110\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3874 - accuracy: 0.8645 - val_loss: 0.5376 - val_accuracy: 0.8090\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3854 - accuracy: 0.8650 - val_loss: 0.5378 - val_accuracy: 0.8117\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3840 - accuracy: 0.8655 - val_loss: 0.5360 - val_accuracy: 0.8117\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3826 - accuracy: 0.8662 - val_loss: 0.5364 - val_accuracy: 0.8130\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3810 - accuracy: 0.8658 - val_loss: 0.5379 - val_accuracy: 0.8110\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3791 - accuracy: 0.8665 - val_loss: 0.5366 - val_accuracy: 0.8117\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3781 - accuracy: 0.8670 - val_loss: 0.5391 - val_accuracy: 0.8123\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3763 - accuracy: 0.8672 - val_loss: 0.5442 - val_accuracy: 0.8115\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3752 - accuracy: 0.8679 - val_loss: 0.5365 - val_accuracy: 0.8110\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3738 - accuracy: 0.8690 - val_loss: 0.5388 - val_accuracy: 0.8140\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3720 - accuracy: 0.8700 - val_loss: 0.5372 - val_accuracy: 0.8120\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3706 - accuracy: 0.8704 - val_loss: 0.5469 - val_accuracy: 0.8112\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3693 - accuracy: 0.8710 - val_loss: 0.5413 - val_accuracy: 0.8158\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3682 - accuracy: 0.8698 - val_loss: 0.5426 - val_accuracy: 0.8125\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3666 - accuracy: 0.8713 - val_loss: 0.5421 - val_accuracy: 0.8085\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3656 - accuracy: 0.8709 - val_loss: 0.5416 - val_accuracy: 0.8138\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3642 - accuracy: 0.8722 - val_loss: 0.5421 - val_accuracy: 0.8115\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3629 - accuracy: 0.8728 - val_loss: 0.5446 - val_accuracy: 0.8108\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3616 - accuracy: 0.8728 - val_loss: 0.5422 - val_accuracy: 0.8102\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3605 - accuracy: 0.8732 - val_loss: 0.5440 - val_accuracy: 0.8123\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3592 - accuracy: 0.8736 - val_loss: 0.5450 - val_accuracy: 0.8133\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3579 - accuracy: 0.8741 - val_loss: 0.5457 - val_accuracy: 0.8135\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3570 - accuracy: 0.8747 - val_loss: 0.5510 - val_accuracy: 0.8080\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3556 - accuracy: 0.8743 - val_loss: 0.5471 - val_accuracy: 0.8102\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3546 - accuracy: 0.8758 - val_loss: 0.5481 - val_accuracy: 0.8117\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3533 - accuracy: 0.8755 - val_loss: 0.5461 - val_accuracy: 0.8130\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.5498 - val_accuracy: 0.8110\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3509 - accuracy: 0.8764 - val_loss: 0.5487 - val_accuracy: 0.8142\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3500 - accuracy: 0.8772 - val_loss: 0.5476 - val_accuracy: 0.8123\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3492 - accuracy: 0.8771 - val_loss: 0.5469 - val_accuracy: 0.8140\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3479 - accuracy: 0.8778 - val_loss: 0.5483 - val_accuracy: 0.8138\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3465 - accuracy: 0.8781 - val_loss: 0.5536 - val_accuracy: 0.8090\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3456 - accuracy: 0.8784 - val_loss: 0.5533 - val_accuracy: 0.8105\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3447 - accuracy: 0.8781 - val_loss: 0.5509 - val_accuracy: 0.8123\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3439 - accuracy: 0.8791 - val_loss: 0.5528 - val_accuracy: 0.8090\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3424 - accuracy: 0.8792 - val_loss: 0.5511 - val_accuracy: 0.8120\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3416 - accuracy: 0.8801 - val_loss: 0.5553 - val_accuracy: 0.8110\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3406 - accuracy: 0.8804 - val_loss: 0.5595 - val_accuracy: 0.8105\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3393 - accuracy: 0.8816 - val_loss: 0.5544 - val_accuracy: 0.8148\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3384 - accuracy: 0.8818 - val_loss: 0.5565 - val_accuracy: 0.8110\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3375 - accuracy: 0.8813 - val_loss: 0.5656 - val_accuracy: 0.8112\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3366 - accuracy: 0.8824 - val_loss: 0.5571 - val_accuracy: 0.8102\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3357 - accuracy: 0.8829 - val_loss: 0.5665 - val_accuracy: 0.8067\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.5613 - val_accuracy: 0.8120\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3334 - accuracy: 0.8830 - val_loss: 0.5619 - val_accuracy: 0.8127\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3332 - accuracy: 0.8831 - val_loss: 0.5660 - val_accuracy: 0.8105\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3319 - accuracy: 0.8833 - val_loss: 0.5605 - val_accuracy: 0.8105\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3305 - accuracy: 0.8840 - val_loss: 0.5658 - val_accuracy: 0.8087\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3299 - accuracy: 0.8853 - val_loss: 0.5691 - val_accuracy: 0.8052\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3289 - accuracy: 0.8848 - val_loss: 0.5645 - val_accuracy: 0.8087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3280 - accuracy: 0.8854 - val_loss: 0.5632 - val_accuracy: 0.8077\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3272 - accuracy: 0.8855 - val_loss: 0.5646 - val_accuracy: 0.8115\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3263 - accuracy: 0.8857 - val_loss: 0.5660 - val_accuracy: 0.8127\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3250 - accuracy: 0.8873 - val_loss: 0.5707 - val_accuracy: 0.8070\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3240 - accuracy: 0.8867 - val_loss: 0.5650 - val_accuracy: 0.8115\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3232 - accuracy: 0.8861 - val_loss: 0.5654 - val_accuracy: 0.8123\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3224 - accuracy: 0.8881 - val_loss: 0.5699 - val_accuracy: 0.8100\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3216 - accuracy: 0.8873 - val_loss: 0.5727 - val_accuracy: 0.8037\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3206 - accuracy: 0.8884 - val_loss: 0.5724 - val_accuracy: 0.8133\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3195 - accuracy: 0.8887 - val_loss: 0.5720 - val_accuracy: 0.8112\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3184 - accuracy: 0.8891 - val_loss: 0.5724 - val_accuracy: 0.8123\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3177 - accuracy: 0.8896 - val_loss: 0.5689 - val_accuracy: 0.8140\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3168 - accuracy: 0.8895 - val_loss: 0.5770 - val_accuracy: 0.8070\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3157 - accuracy: 0.8908 - val_loss: 0.5779 - val_accuracy: 0.8100\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3150 - accuracy: 0.8897 - val_loss: 0.5725 - val_accuracy: 0.8125\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3142 - accuracy: 0.8915 - val_loss: 0.5771 - val_accuracy: 0.8105\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3131 - accuracy: 0.8911 - val_loss: 0.5748 - val_accuracy: 0.8133\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3122 - accuracy: 0.8919 - val_loss: 0.5738 - val_accuracy: 0.8102\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3113 - accuracy: 0.8917 - val_loss: 0.5791 - val_accuracy: 0.8098\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3100 - accuracy: 0.8929 - val_loss: 0.5759 - val_accuracy: 0.8115\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3094 - accuracy: 0.8928 - val_loss: 0.5770 - val_accuracy: 0.8095\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3084 - accuracy: 0.8929 - val_loss: 0.5822 - val_accuracy: 0.8138\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3077 - accuracy: 0.8936 - val_loss: 0.5775 - val_accuracy: 0.8138\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3068 - accuracy: 0.8939 - val_loss: 0.5778 - val_accuracy: 0.8108\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3057 - accuracy: 0.8944 - val_loss: 0.5818 - val_accuracy: 0.8117\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3048 - accuracy: 0.8944 - val_loss: 0.5840 - val_accuracy: 0.8098\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3038 - accuracy: 0.8950 - val_loss: 0.5843 - val_accuracy: 0.8123\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3029 - accuracy: 0.8954 - val_loss: 0.5879 - val_accuracy: 0.8125\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3021 - accuracy: 0.8955 - val_loss: 0.5871 - val_accuracy: 0.8133\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3010 - accuracy: 0.8956 - val_loss: 0.5910 - val_accuracy: 0.8115\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3001 - accuracy: 0.8970 - val_loss: 0.5884 - val_accuracy: 0.8092\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2994 - accuracy: 0.8968 - val_loss: 0.5892 - val_accuracy: 0.8085\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2983 - accuracy: 0.8977 - val_loss: 0.5908 - val_accuracy: 0.8102\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2977 - accuracy: 0.8980 - val_loss: 0.5898 - val_accuracy: 0.8073\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2966 - accuracy: 0.8989 - val_loss: 0.5890 - val_accuracy: 0.8092\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2955 - accuracy: 0.8981 - val_loss: 0.5908 - val_accuracy: 0.8105\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2947 - accuracy: 0.8990 - val_loss: 0.6003 - val_accuracy: 0.8055\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2936 - accuracy: 0.8995 - val_loss: 0.5908 - val_accuracy: 0.8085\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2927 - accuracy: 0.9001 - val_loss: 0.5924 - val_accuracy: 0.8083\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2919 - accuracy: 0.9000 - val_loss: 0.5927 - val_accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 23us/step\n",
      "Training Loss: 0.286 \n",
      "Training Accuracy: 0.903\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 27us/step\n",
      "Test Loss: 0.593 \n",
      "Test Accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
